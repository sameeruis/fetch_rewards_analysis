{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading USER_TAKEHOME Dataset into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of USER_TAKEHOME Dataset\n",
      "                         ID               CREATED_DATE  \\\n",
      "0  5ef3b4f17053ab141787697d  2020-06-24 20:17:54.000 Z   \n",
      "1  5ff220d383fcfc12622b96bc  2021-01-03 19:53:55.000 Z   \n",
      "2  6477950aa55bb77a0e27ee10  2023-05-31 18:42:18.000 Z   \n",
      "3  658a306e99b40f103b63ccf8  2023-12-26 01:46:22.000 Z   \n",
      "4  653cf5d6a225ea102b7ecdc2  2023-10-28 11:51:50.000 Z   \n",
      "\n",
      "                  BIRTH_DATE STATE LANGUAGE  GENDER  \n",
      "0  2000-08-11 00:00:00.000 Z    CA   es-419  female  \n",
      "1  2001-09-24 04:00:00.000 Z    PA       en  female  \n",
      "2  1994-10-28 00:00:00.000 Z    FL   es-419  female  \n",
      "3                        NaN    NC       en     NaN  \n",
      "4  1972-03-19 00:00:00.000 Z    PA       en  female  \n"
     ]
    }
   ],
   "source": [
    "#Import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Load the USER_TAKEHOME.csv\n",
    "users = pd.read_csv('USER_TAKEHOME.csv')\n",
    "\n",
    "#Display the first few rows of the Dataset to understand the structure \n",
    "print('Preview of USER_TAKEHOME Dataset')\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in the USER_TAKEHOME Dataset:\n",
      "ID                  0\n",
      "CREATED_DATE        0\n",
      "BIRTH_DATE       3675\n",
      "STATE            4812\n",
      "LANGUAGE        30508\n",
      "GENDER           5892\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for Missing Values in the dataset\n",
    "print('Missing Values in the USER_TAKEHOME Dataset:')\n",
    "print(users.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Duplicates in USER_TAKEHOME Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Duplicate Rows in the Dataset:\n",
      "0\n",
      "\n",
      "Number of Duplicate Rows After Removal:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check for duplicate rows\n",
    "print(\"Number of Duplicate Rows in the Dataset:\")\n",
    "print(users.duplicated().sum())\n",
    "\n",
    "# Step 2: Remove duplicate rows\n",
    "users = users.drop_duplicates()\n",
    "\n",
    "# Step 3: Confirm duplicates are removed\n",
    "print(\"\\nNumber of Duplicate Rows After Removal:\")\n",
    "print(users.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of AGE based on the BIRTH_DATE Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Column Preview:\n",
      "0    25.0\n",
      "1    24.0\n",
      "2    31.0\n",
      "3     NaN\n",
      "4    53.0\n",
      "Name: AGE, dtype: float64\n",
      "\n",
      "Number of Missing or Unrealistic Ages:\n",
      "3675\n"
     ]
    }
   ],
   "source": [
    "# Convert BIRTH_DATE to datetime format\n",
    "users['BIRTH_DATE'] = pd.to_datetime(users['BIRTH_DATE'], errors='coerce')\n",
    "\n",
    "# Calculate the age based on BIRTH_DATE\n",
    "current_year = pd.Timestamp.now().year\n",
    "users['AGE'] = current_year - users['BIRTH_DATE'].dt.year\n",
    "\n",
    "# Preview the AGE column\n",
    "print(\"Age Column Preview:\")\n",
    "print(users['AGE'].head())\n",
    "\n",
    "# Check for invalid ages (missing or unrealistic values)\n",
    "print(\"\\nNumber of Missing or Unrealistic Ages:\")\n",
    "print(users['AGE'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missing Ages After Imputation:\n",
      "0\n",
      "\n",
      "Preview of Updated AGE Column:\n",
      "0    25.0\n",
      "1    24.0\n",
      "2    31.0\n",
      "3    -1.0\n",
      "4    53.0\n",
      "Name: AGE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Impute missing ages with -1 to clearly indicate missing data while retaining the rows\n",
    "users['AGE'] = users['AGE'].fillna(-1)\n",
    "\n",
    "# Confirm Changes: Ensure no missing values remain in the AGE column\n",
    "print(\"Number of Missing Ages After Imputation:\")\n",
    "print(users['AGE'].isnull().sum())\n",
    "\n",
    "# Preview the updated AGE Column to verify changes\n",
    "print(\"\\nPreview of Updated AGE Column:\")\n",
    "print(users['AGE'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Handling Missing Ages\n",
    "# - Missing age values are imputed with -1 as a placeholder to clearly indicate missing data.\n",
    "# - This approach retains all rows in the dataset and avoids data loss, ensuring other fields remain intact.\n",
    "# - Rows with AGE = -1 can be easily filtered out during future analysis of age-related patterns.\n",
    "# - This placeholder can be updated later with actual values or replaced with a more accurate imputation if additional data becomes available.\n",
    "\n",
    "# Example: Filtering users with valid ages for age-based analysis\n",
    "# valid_age_users = users[users['AGE'] >= 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning of the CREATED_DATE Column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Invalid CREATED_DATE Values: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert CREATED_DATE to datetime format\n",
    "users['CREATED_DATE'] = pd.to_datetime(users['CREATED_DATE'], errors='coerce')\n",
    "\n",
    "# Check for missing or invalid dates after conversion\n",
    "invalid_dates = users[users['CREATED_DATE'].isnull()]\n",
    "\n",
    "# Display the number of invalid CREATED_DATE values and a sample\n",
    "print(f\"Number of Invalid CREATED_DATE Values: {invalid_dates.shape[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Clean the GENDER Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values in GENDER Column Before Cleaning:\n",
      "['female' nan 'male' 'non_binary' 'transgender' 'prefer_not_to_say'\n",
      " 'not_listed' 'Non-Binary' 'unknown' 'not_specified'\n",
      " \"My gender isn't listed\" 'Prefer not to say']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Inspect unique values in the GENDER column to identify inconsistencies\n",
    "print(\"Unique Values in GENDER Column Before Cleaning:\")\n",
    "print(users['GENDER'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Values in GENDER Column after Standardization:\n",
      "['FEMALE' nan 'MALE' 'NON_BINARY' 'TRANSGENDER' 'PREFER_NOT_TO_SAY'\n",
      " 'NOT_LISTED' 'NON-BINARY' 'UNKNOWN' 'NOT_SPECIFIED'\n",
      " \"MY GENDER ISN'T LISTED\" 'PREFER NOT TO SAY']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Standardize the GENDER values (e.g., handle case sensitivity)\n",
    "users['GENDER'] = users['GENDER'].str.strip().str.upper()\n",
    "\n",
    "# Check Unique values after standardization\n",
    "print(\"\\nUnique Values in GENDER Column after Standardization:\")\n",
    "print(users['GENDER'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Unique Values in GENDER Column After Cleaning:\n",
      "['FEMALE' 'unknown' 'MALE' 'NON_BINARY' 'TRANSGENDER' 'PREFER_NOT_TO_SAY'\n",
      " 'NOT_LISTED' 'NON-BINARY' 'UNKNOWN' 'NOT_SPECIFIED'\n",
      " \"MY GENDER ISN'T LISTED\" 'PREFER NOT TO SAY']\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Handle missing values in GENDER by replacing with 'unknown'\n",
    "users['GENDER'] = users['GENDER'].fillna('unknown')\n",
    "\n",
    "# Validate the final unique values\n",
    "print(\"\\nFinal Unique Values in GENDER Column After Cleaning:\")\n",
    "print(users['GENDER'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Unique Values after Standardization:\n",
      "['FEMALE' 'unknown' 'MALE' 'NON_BINARY' 'TRANSGENDER' 'PREFER_NOT_TO_SAY'\n",
      " 'NOT_LISTED' 'NON-BINARY' 'UNKNOWN' 'NOT_SPECIFIED'\n",
      " \"MY GENDER ISN'T LISTED\" 'PREFER NOT TO SAY']\n"
     ]
    }
   ],
   "source": [
    "# Defining a mapping for inconsistent labels to standardized values\n",
    "gender_mapping = {\n",
    "    'non_binary' : 'non_binary', 'non-binary' : 'non-binary', 'prefer_not_to_say' : 'prefer not to say',\n",
    "    \"my gender isn't listed\" : 'not listed', 'not_listed' : 'not listed', 'not_specified' : 'unknown'\n",
    "    # Treat \"not specified\" as \"unknown\" for simplicity\n",
    "}\n",
    "\n",
    "# Apply the mapping to the GENDER Column\n",
    "users['GENDER'] = users['GENDER'].replace(gender_mapping)\n",
    "\n",
    "# Validate the final unique values after standardization\n",
    "print(\"\\nFinal Unique Values after Standardization:\")\n",
    "print(users['GENDER'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Clean STATE Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values in STATE Column Before Cleaning:\n",
      "['CA' 'PA' 'FL' 'NC' 'NY' 'IN' nan 'OH' 'TX' 'NM' 'PR' 'CO' 'AZ' 'RI' 'MO'\n",
      " 'NJ' 'MA' 'TN' 'LA' 'NH' 'WI' 'IA' 'GA' 'VA' 'DC' 'KY' 'SC' 'MN' 'WV'\n",
      " 'DE' 'MI' 'IL' 'MS' 'WA' 'KS' 'CT' 'OR' 'UT' 'MD' 'OK' 'NE' 'NV' 'AL'\n",
      " 'AK' 'AR' 'HI' 'ME' 'ND' 'ID' 'WY' 'MT' 'SD' 'VT']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Inspect unique values in the STATE Column\n",
    "print(\"Unique Values in STATE Column Before Cleaning:\")\n",
    "print(users['STATE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values in STATE Column After Replacing Missing Values:\n",
      "['CA' 'PA' 'FL' 'NC' 'NY' 'IN' 'unkown' 'OH' 'TX' 'NM' 'PR' 'CO' 'AZ' 'RI'\n",
      " 'MO' 'NJ' 'MA' 'TN' 'LA' 'NH' 'WI' 'IA' 'GA' 'VA' 'DC' 'KY' 'SC' 'MN'\n",
      " 'WV' 'DE' 'MI' 'IL' 'MS' 'WA' 'KS' 'CT' 'OR' 'UT' 'MD' 'OK' 'NE' 'NV'\n",
      " 'AL' 'AK' 'AR' 'HI' 'ME' 'ND' 'ID' 'WY' 'MT' 'SD' 'VT']\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values in STATE with 'unknown'\n",
    "users['STATE'] = users['STATE'].fillna('unkown')\n",
    "\n",
    "# Check the updated unique values\n",
    "print(\"Unique Values in STATE Column After Replacing Missing Values:\")\n",
    "print(users['STATE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Invalid State Entries:\n",
      "['unkown']\n"
     ]
    }
   ],
   "source": [
    "# Define a list of valid U.S State codes\n",
    "valid_states = [\n",
    "    'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL',\n",
    "    'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT',\n",
    "    'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI',\n",
    "    'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY', 'PR', 'DC'\n",
    "]\n",
    "\n",
    "# Identify invalid state entries\n",
    "invalid_states = users[~users['STATE'].isin(valid_states) & (users['STATE'] != 'unknown')]['STATE'].unique()\n",
    "\n",
    "# Display invalid states\n",
    "print(\"\\nInvalid State Entries:\")\n",
    "print(invalid_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Values in STATE Column After Cleaning:\n",
      "['CA' 'PA' 'FL' 'NC' 'NY' 'IN' 'unknown' 'OH' 'TX' 'NM' 'PR' 'CO' 'AZ'\n",
      " 'RI' 'MO' 'NJ' 'MA' 'TN' 'LA' 'NH' 'WI' 'IA' 'GA' 'VA' 'DC' 'KY' 'SC'\n",
      " 'MN' 'WV' 'DE' 'MI' 'IL' 'MS' 'WA' 'KS' 'CT' 'OR' 'UT' 'MD' 'OK' 'NE'\n",
      " 'NV' 'AL' 'AK' 'AR' 'HI' 'ME' 'ND' 'ID' 'WY' 'MT' 'SD' 'VT']\n"
     ]
    }
   ],
   "source": [
    "# Replace invalid state entries with 'unknown'\n",
    "users.loc[~users['STATE'].isin(valid_states) & (users['STATE'] != 'unknown'), 'STATE'] = 'unknown'\n",
    "\n",
    "# Validate changes\n",
    "print(\"\\nUnique Values in STATE Column After Cleaning:\")\n",
    "print(users['STATE'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Clean LANGUAGE Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values in LANGUAGE Column Before Cleaning:\n",
      "['es-419' 'en' nan]\n"
     ]
    }
   ],
   "source": [
    "# Inspect unique values in LANGUAGE column\n",
    "print(\"Unique Values in LANGUAGE Column Before Cleaning:\")\n",
    "print(users['LANGUAGE'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Unique Values in LANGUAGE Column After Cleaning:\n",
      "['SPANISH' 'ENGLISH' 'unknown']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define a mapping dictionary for standardizing language values\n",
    "language_mapping = {\n",
    "    'es-419': 'SPANISH',\n",
    "    'en': 'ENGLISH'\n",
    "}\n",
    "\n",
    "# Apply the mapping to standardize LANGUAGE values\n",
    "users['LANGUAGE'] = users['LANGUAGE'].replace(language_mapping)\n",
    "\n",
    "# Step 2: Handle missing values by replacing NaN with 'unknown'\n",
    "users['LANGUAGE'] = users['LANGUAGE'].fillna('unknown')\n",
    "\n",
    "# Step 3: Validate the final unique values in the LANGUAGE column\n",
    "print(\"\\nFinal Unique Values in LANGUAGE Column After Cleaning:\")\n",
    "print(users['LANGUAGE'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Column Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types in USER_TAKEHOME Dataset:\n",
      "ID                           object\n",
      "CREATED_DATE    datetime64[ns, UTC]\n",
      "BIRTH_DATE      datetime64[ns, UTC]\n",
      "STATE                        object\n",
      "LANGUAGE                     object\n",
      "GENDER                       object\n",
      "AGE                         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display column data types\n",
    "print(\"Data Types in USER_TAKEHOME Dataset:\")\n",
    "print(users.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated Data Types in USER_TAKEHOME Dataset:\n",
      "ID                           object\n",
      "CREATED_DATE    datetime64[ns, UTC]\n",
      "BIRTH_DATE      datetime64[ns, UTC]\n",
      "STATE                        object\n",
      "LANGUAGE                     object\n",
      "GENDER                       object\n",
      "AGE                         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert ID to string\n",
    "users['ID'] = users['ID'].astype(str)\n",
    "\n",
    "# Validate changes\n",
    "print(\"\\nUpdated Data Types in USER_TAKEHOME Dataset:\")\n",
    "print(users.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Tranforming of PRODUCTS_TAKEHOME Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Information about PRODUCTS_TAKEHOME Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 845552 entries, 0 to 845551\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   CATEGORY_1    845441 non-null  object \n",
      " 1   CATEGORY_2    844128 non-null  object \n",
      " 2   CATEGORY_3    784986 non-null  object \n",
      " 3   CATEGORY_4    67459 non-null   object \n",
      " 4   MANUFACTURER  619078 non-null  object \n",
      " 5   BRAND         619080 non-null  object \n",
      " 6   BARCODE       841527 non-null  float64\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 45.2+ MB\n",
      "None\n",
      "\n",
      "Missing Values Per Column in PRODUCTS_TAKEHOME Dataset:\n",
      "CATEGORY_1         111\n",
      "CATEGORY_2        1424\n",
      "CATEGORY_3       60566\n",
      "CATEGORY_4      778093\n",
      "MANUFACTURER    226474\n",
      "BRAND           226472\n",
      "BARCODE           4025\n",
      "dtype: int64\n",
      "\n",
      "Preview of PRODUCTS_TAKEHOME Dataset:\n",
      "          CATEGORY_1              CATEGORY_2                   CATEGORY_3  \\\n",
      "0  Health & Wellness           Sexual Health  Conductivity Gels & Lotions   \n",
      "1             Snacks           Puffed Snacks         Cheese Curls & Puffs   \n",
      "2  Health & Wellness               Hair Care        Hair Care Accessories   \n",
      "3  Health & Wellness               Oral Care                   Toothpaste   \n",
      "4  Health & Wellness  Medicines & Treatments               Essential Oils   \n",
      "\n",
      "  CATEGORY_4                                       MANUFACTURER  \\\n",
      "0        NaN                                                NaN   \n",
      "1        NaN                                                NaN   \n",
      "2        NaN                           PLACEHOLDER MANUFACTURER   \n",
      "3        NaN                                  COLGATE-PALMOLIVE   \n",
      "4        NaN  MAPLE HOLISTICS AND HONEYDEW PRODUCTS INTERCHA...   \n",
      "\n",
      "             BRAND       BARCODE  \n",
      "0              NaN  7.964944e+11  \n",
      "1              NaN  2.327801e+10  \n",
      "2          ELECSOP  4.618178e+11  \n",
      "3          COLGATE  3.500047e+10  \n",
      "4  MAPLE HOLISTICS  8.068109e+11  \n"
     ]
    }
   ],
   "source": [
    "# Load the PRODUCTS_TAKEHOME dataset\n",
    "products = pd.read_csv('PRODUCTS_TAKEHOME.csv')\n",
    "\n",
    "# Step 1: Inspect PRODUCTS_TAKEHOME dataset\n",
    "# Display basic information about the dataset\n",
    "print(\"Basic Information about PRODUCTS_TAKEHOME Dataset:\")\n",
    "print(products.info())\n",
    "\n",
    "# Display missing values in each column\n",
    "print(\"\\nMissing Values Per Column in PRODUCTS_TAKEHOME Dataset:\")\n",
    "print(products.isnull().sum())\n",
    "\n",
    "# Preview the first few rows of the dataset\n",
    "print(\"\\nPreview of PRODUCTS_TAKEHOME Dataset:\")\n",
    "print(products.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Duplicate Rows in PRODUCTS_TAKEHOME Dataset:\n",
      "215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows_products = products.duplicated().sum()\n",
    "print(\"\\nNumber of Duplicate Rows in PRODUCTS_TAKEHOME Dataset:\")\n",
    "print(duplicate_rows_products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Duplicate Rows after Removal:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Remove Duplicate rows\n",
    "products = products.drop_duplicates()\n",
    "\n",
    "# Confirm changes\n",
    "print(\"\\nNumber of Duplicate Rows after Removal:\")\n",
    "print(products.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values After Cleaning:\n",
      "CATEGORY_1         0\n",
      "CATEGORY_2         0\n",
      "CATEGORY_3         0\n",
      "CATEGORY_4         0\n",
      "MANUFACTURER       0\n",
      "BRAND              0\n",
      "BARCODE         3968\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handling Missing Values in PRODUCTS_TAKEHOME Dataset\n",
    "\n",
    "# Assumptions:\n",
    "# 1. The 'BARCODE' column is a key identifier for products. Missing barcodes make it impossible to uniquely identify a product,\n",
    "#    so rows with missing BARCODE values will be dropped.\n",
    "# 2. Missing values in category columns ('CATEGORY_1', 'CATEGORY_2', etc.) indicate incomplete product information. \n",
    "#    These will be replaced with 'unknown' to explicitly mark missing data while retaining rows for further analysis.\n",
    "# 3. Missing values in 'MANUFACTURER' and 'BRAND' columns represent unavailable brand and manufacturer data.\n",
    "#    Replacing these with 'unknown' helps preserve rows while indicating missing details.\n",
    "\n",
    "# Replace missing values in category and textual columns with 'unknown'\n",
    "category_columns = ['CATEGORY_1', 'CATEGORY_2', 'CATEGORY_3', 'CATEGORY_4', 'MANUFACTURER', 'BRAND']\n",
    "products[category_columns] = products[category_columns].fillna('unknown')\n",
    "\n",
    "# Confirm changes\n",
    "print(\"\\nMissing Values After Cleaning:\")\n",
    "print(products.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Rows Before Dropping Missing BARCODEs: 845337\n",
      "Number of Rows After Dropping Missing BARCODEs: 841369\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing BARCODE\n",
    "# Assumptions:\n",
    "# 1. The BARCODE column is critical for uniquely identifying products.\n",
    "# 2. Rows with missing BARCODE values are considered incomplete and not useful for analysis.\n",
    "\n",
    "# Action:\n",
    "# - Drop rows where BARCODE is missing to preserve dataset integrity.\n",
    "\n",
    "# Drop missing BARCODE rows\n",
    "products_before = products.shape[0]\n",
    "products = products[products['BARCODE'].notnull()]\n",
    "products_after = products.shape[0]\n",
    "\n",
    "# Confirm changes\n",
    "print(f\"\\nNumber of Rows Before Dropping Missing BARCODEs: {products_before}\")\n",
    "print(f\"Number of Rows After Dropping Missing BARCODEs: {products_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Duplicate BARCODEs: 54\n",
      "\n",
      "Sample of Duplicated BARCODE Rows:\n",
      "              CATEGORY_1    CATEGORY_2           CATEGORY_3  \\\n",
      "162    Health & Wellness  Hair Removal  Shaving Gel & Cream   \n",
      "28421  Health & Wellness     Hair Care           Hair Color   \n",
      "36017             Snacks         Candy   Candy Variety Pack   \n",
      "37152             Snacks         Candy     Confection Candy   \n",
      "56987             Snacks  Nuts & Seeds              Almonds   \n",
      "\n",
      "                        CATEGORY_4              MANUFACTURER            BRAND  \\\n",
      "162    Women's Shaving Gel & Cream  PLACEHOLDER MANUFACTURER          PRORASO   \n",
      "28421                      unknown                    HENKEL      SCHWARZKOPF   \n",
      "36017                      unknown       THE HERSHEY COMPANY        HERSHEY'S   \n",
      "37152                      unknown        PERFETTI VAN MELLE           MENTOS   \n",
      "56987                      unknown  PLACEHOLDER MANUFACTURER  BRAND NOT KNOWN   \n",
      "\n",
      "            BARCODE  \n",
      "162    8.019914e+07  \n",
      "28421  5.233692e+10  \n",
      "36017  3.422007e+06  \n",
      "37152  8.730629e+07  \n",
      "56987  2.015908e+07  \n"
     ]
    }
   ],
   "source": [
    "# Check for duplicated BARCODEs\n",
    "# Assumptions:\n",
    "# 1. BARCODE is expected to uniquely identify each product.\n",
    "# 2. Duplicate BARCODEs could indicate duplicate or inconsistent entries.\n",
    "\n",
    "# Action:\n",
    "# - Identify duplicate BARCODEs and inspect their details for further action.\n",
    "\n",
    "# Identify duplicates\n",
    "duplicated_barcodes = products[products['BARCODE'].duplicated(keep=False)]\n",
    "\n",
    "# Count and display a sample of duplicate BARCODEs\n",
    "print(f\"\\nNumber of Duplicate BARCODEs: {duplicated_barcodes.shape[0]}\")\n",
    "print(\"\\nSample of Duplicated BARCODE Rows:\")\n",
    "print(duplicated_barcodes.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Rows Before Dropping Duplicates: 841369\n",
      "Number of Rows After Dropping Duplicates: 841342\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate BARCODE rows\n",
    "# Assumptions:\n",
    "# 1. BARCODE should uniquely identify products.\n",
    "# 2. Duplicate barcodes are considered data inconsistencies and will be dropped, keeping the first occurrence.\n",
    "\n",
    "# Action:\n",
    "# - Drop duplicate rows based on the BARCODE column.\n",
    "\n",
    "products_before = products.shape[0]\n",
    "products = products.drop_duplicates(subset='BARCODE', keep='first')\n",
    "products_after = products.shape[0]\n",
    "\n",
    "# Verify changes\n",
    "print(f\"\\nNumber of Rows Before Dropping Duplicates: {products_before}\")\n",
    "print(f\"Number of Rows After Dropping Duplicates: {products_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Duplicate Barcodes\n",
    "# Assumptions:\n",
    "# - The BARCODE column should uniquely identify each product.\n",
    "# - Duplicate rows with the same BARCODE are likely errors or redundant entries.\n",
    "# - Keeping the first occurrence ensures data consistency while minimizing loss.\n",
    "\n",
    "# Findings:\n",
    "# - A total of 27 duplicate rows were identified and removed based on the BARCODE column.\n",
    "\n",
    "# Action Taken:\n",
    "# - Duplicate rows with the same BARCODE were dropped, retaining the first occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values Per Column After Cleaning:\n",
      "CATEGORY_1      0\n",
      "CATEGORY_2      0\n",
      "CATEGORY_3      0\n",
      "CATEGORY_4      0\n",
      "MANUFACTURER    0\n",
      "BRAND           0\n",
      "BARCODE         0\n",
      "dtype: int64\n",
      "\n",
      "Number of Duplicate Barcodes Remaining: 0\n"
     ]
    }
   ],
   "source": [
    "# Verify no remaining missing values\n",
    "print(\"\\nMissing Values Per Column After Cleaning:\")\n",
    "print(products.isnull().sum())\n",
    "\n",
    "# Verify no duplicates remain in the BARCODE column\n",
    "duplicate_barcodes_check = products['BARCODE'].duplicated().sum()\n",
    "print(f\"\\nNumber of Duplicate Barcodes Remaining: {duplicate_barcodes_check}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-Cleaning Validation:\n",
    "# After removing duplicates, the output confirmed that there are now 0 duplicate BARCODEs remaining in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization and Validation of the PRODUCT_TAKEHOME Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Values in CATEGORY_1 Column Before Validation:\n",
      "['Health & Wellness' 'Snacks' 'Beverages' 'Pantry' 'Alcohol'\n",
      " 'Apparel & Accessories' 'Restaurant' 'Needs Review' 'Dairy'\n",
      " 'Home & Garden' 'unknown' 'Household Supplies' 'Meat & Seafood'\n",
      " 'Deli & Bakery' 'Sporting Goods' 'Produce' 'Office & School' 'Frozen'\n",
      " 'Arts & Entertainment' 'Animals & Pet Supplies' 'Electronics' 'Beauty'\n",
      " 'Toys & Games' 'Mature' 'Vehicles & Parts' 'Baby & Toddler'\n",
      " 'Luggage & Bags' 'Media']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check unique values in CATEGORY_1\n",
    "print(\"\\nUnique Values in CATEGORY_1 Column Before Validation:\")\n",
    "print(products['CATEGORY_1'].unique())\n",
    "\n",
    "# Identify inconsistencies (e.g., unexpected or case-sensitive values)\n",
    "# You can note down any anomalies from this output for further action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Rows with 'Needs Review' in CATEGORY_1: 547\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Count occurrences of 'Needs Review' in CATEGORY_1\n",
    "needs_review_count = products[products['CATEGORY_1'] == 'Needs Review'].shape[0]\n",
    "print(f\"\\nNumber of Rows with 'Needs Review' in CATEGORY_1: {needs_review_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Unique Values in CATEGORY_1 Column After Validation:\n",
      "['Health & Wellness' 'Snacks' 'Beverages' 'Pantry' 'Alcohol'\n",
      " 'Apparel & Accessories' 'Restaurant' 'unknown' 'Dairy' 'Home & Garden'\n",
      " 'Household Supplies' 'Meat & Seafood' 'Deli & Bakery' 'Sporting Goods'\n",
      " 'Produce' 'Office & School' 'Frozen' 'Arts & Entertainment'\n",
      " 'Animals & Pet Supplies' 'Electronics' 'Beauty' 'Toys & Games' 'Mature'\n",
      " 'Vehicles & Parts' 'Baby & Toddler' 'Luggage & Bags' 'Media']\n"
     ]
    }
   ],
   "source": [
    "# Since 'Needs Review' suggests it’s a placeholder and doesn’t belong to a specific category,\n",
    "# it’s better to replace it with 'unknown' to maintain consistency.\n",
    "# Replace 'Needs Review' with 'unknown'\n",
    "products['CATEGORY_1'] = products['CATEGORY_1'].replace('Needs Review', 'unknown')\n",
    "\n",
    "# Confirm Final Unique Values\n",
    "print(\"\\nFinal Unique Values in CATEGORY_1 Column After Validation:\")\n",
    "print(products['CATEGORY_1'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Unique Values in CATEGORY_1 Column After Standardization:\n",
      "['Health & Wellness' 'Snacks' 'Beverages' 'Pantry' 'Alcohol'\n",
      " 'Apparel & Accessories' 'Restaurant' 'Unknown' 'Dairy' 'Home & Garden'\n",
      " 'Household Supplies' 'Meat & Seafood' 'Deli & Bakery' 'Sporting Goods'\n",
      " 'Produce' 'Office & School' 'Frozen' 'Arts & Entertainment'\n",
      " 'Animals & Pet Supplies' 'Electronics' 'Beauty' 'Toys & Games' 'Mature'\n",
      " 'Vehicles & Parts' 'Baby & Toddler' 'Luggage & Bags' 'Media']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Standardize CATEGORY_1 values\n",
    "# - Remove leading/trailing spaces using .str.strip()\n",
    "# - Convert values to title case using .str.title() to ensure uniformity\n",
    "products['CATEGORY_1'] = products['CATEGORY_1'].str.strip()\n",
    "products['CATEGORY_1'] = products['CATEGORY_1'].str.title()\n",
    "\n",
    "# Step 2: Validate unique values in CATEGORY_1 after standardization\n",
    "print(\"\\nFinal Unique Values in CATEGORY_1 Column After Standardization:\")\n",
    "print(products['CATEGORY_1'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Values in CATEGORY_2 Before Standardization:\n",
      "['Sexual Health' 'Puffed Snacks' 'Hair Care' 'Oral Care'\n",
      " 'Medicines & Treatments' 'Deodorant & Antiperspirant' 'Snack Bars'\n",
      " 'Bath & Body' 'Nuts & Seeds' 'Candy' 'Cookies' 'Variety Snack Packs'\n",
      " 'Hair Removal' 'Medical Supplies & Equipment' 'Chips' 'Snack Cakes'\n",
      " 'Skin Care' 'Dessert Toppings' 'Eye Care' 'Fruit & Vegetable Snacks'\n",
      " 'Snack Mixes' 'Crackers' 'Jerky & Dried Meat'\n",
      " 'Topical Muscle & Joint Relief Treatments' 'Foot Care' 'First Aid'\n",
      " 'Ear Care' 'Menstrual Care' 'Pretzels' 'Trail Mix' 'Dips & Salsa'\n",
      " 'Adult Incontinence' 'Water' 'Cereal, Granola, & Toaster Pastries' 'Wine'\n",
      " 'Pudding & Gelatin' 'Clothing' 'Carbonated Soft Drinks'\n",
      " 'Energy & Endurance' 'Beverages' 'unknown' 'Cheese' 'Kitchen & Dining'\n",
      " 'Energy Drinks' 'Packaged Vegetables' 'Household Cleaning Supplies'\n",
      " 'Business & Home Security'\n",
      " 'Hard Seltzers, Sodas, Waters, Lemonades & Teas' 'Beer' 'Fresh Seafood'\n",
      " 'Packaged Meals & Sides' 'Prepared Meals' 'Jewelry' 'Exercise & Fitness'\n",
      " 'Pasta & Noodles' 'Packaged Fruit & Applesauce' 'Fresh Fruits'\n",
      " 'Name Plates' 'Sauces & Marinades' 'Frozen Desserts' 'Spirits'\n",
      " 'Cooking & Baking' 'Athletics' 'Clothing Accessories' 'Plants'\n",
      " 'Musical Instruments' 'Cocktail Prep' 'Beverage Syrups'\n",
      " 'Frozen Pizza & Pizza Snacks' 'Nut Butters & Jam' 'Coffee'\n",
      " 'Fruit & Vegetable Juices' 'Pet Carriers, Crates & Accessories' 'Audio'\n",
      " 'Hardware' 'Fish Supplies' 'Makeup' 'Decor' 'Toys' 'Office Carts'\n",
      " 'Frozen Meat' 'Pet Grooming Supplies' 'Fresh Vegetables' 'Furniture'\n",
      " 'Tobacco Products' 'Soup & Broth' 'Dairy Alternatives'\n",
      " 'Vehicle Storage & Cargo' 'Packaged Seafood' 'Office & Chair Mats'\n",
      " 'Pickled Goods' 'Outdoor Recreation' 'Indoor Games' 'Arts & Crafts'\n",
      " 'À La Carte Item' 'Frozen Appetizers' 'Food Storage' 'Tea'\n",
      " 'Vehicle Maintenance, Care & Decor' 'Games'\n",
      " 'Arcade Equipment & Accessories' 'Baby Toys & Activity Equipment'\n",
      " 'Hard Ciders' 'Luggage Accessories' 'Lawn & Garden' 'Books' 'Condiments'\n",
      " 'Lighting' 'Ice' 'Presentation Supplies' 'Handbag, Wallet & Accessories'\n",
      " 'Emergency Preparedness' 'Music & Recordings' 'Party & Celebration'\n",
      " 'Shoes' 'Pool, Spa & Accessories' 'Baby & Toddler Feeding'\n",
      " 'Malt Beverages' 'Household Appliances' 'Shipping Supplies'\n",
      " 'Frozen Sides' 'Baby Transport']\n",
      "\n",
      "Final Unique Values in CATEGORY_2 After Standardization:\n",
      "['Sexual Health' 'Puffed Snacks' 'Hair Care' 'Oral Care'\n",
      " 'Medicines & Treatments' 'Deodorant & Antiperspirant' 'Snack Bars'\n",
      " 'Bath & Body' 'Nuts & Seeds' 'Candy' 'Cookies' 'Variety Snack Packs'\n",
      " 'Hair Removal' 'Medical Supplies & Equipment' 'Chips' 'Snack Cakes'\n",
      " 'Skin Care' 'Dessert Toppings' 'Eye Care' 'Fruit & Vegetable Snacks'\n",
      " 'Snack Mixes' 'Crackers' 'Jerky & Dried Meat'\n",
      " 'Topical Muscle & Joint Relief Treatments' 'Foot Care' 'First Aid'\n",
      " 'Ear Care' 'Menstrual Care' 'Pretzels' 'Trail Mix' 'Dips & Salsa'\n",
      " 'Adult Incontinence' 'Water' 'Cereal, Granola, & Toaster Pastries' 'Wine'\n",
      " 'Pudding & Gelatin' 'Clothing' 'Carbonated Soft Drinks'\n",
      " 'Energy & Endurance' 'Beverages' 'Unknown' 'Cheese' 'Kitchen & Dining'\n",
      " 'Energy Drinks' 'Packaged Vegetables' 'Household Cleaning Supplies'\n",
      " 'Business & Home Security'\n",
      " 'Hard Seltzers, Sodas, Waters, Lemonades & Teas' 'Beer' 'Fresh Seafood'\n",
      " 'Packaged Meals & Sides' 'Prepared Meals' 'Jewelry' 'Exercise & Fitness'\n",
      " 'Pasta & Noodles' 'Packaged Fruit & Applesauce' 'Fresh Fruits'\n",
      " 'Name Plates' 'Sauces & Marinades' 'Frozen Desserts' 'Spirits'\n",
      " 'Cooking & Baking' 'Athletics' 'Clothing Accessories' 'Plants'\n",
      " 'Musical Instruments' 'Cocktail Prep' 'Beverage Syrups'\n",
      " 'Frozen Pizza & Pizza Snacks' 'Nut Butters & Jam' 'Coffee'\n",
      " 'Fruit & Vegetable Juices' 'Pet Carriers, Crates & Accessories' 'Audio'\n",
      " 'Hardware' 'Fish Supplies' 'Makeup' 'Decor' 'Toys' 'Office Carts'\n",
      " 'Frozen Meat' 'Pet Grooming Supplies' 'Fresh Vegetables' 'Furniture'\n",
      " 'Tobacco Products' 'Soup & Broth' 'Dairy Alternatives'\n",
      " 'Vehicle Storage & Cargo' 'Packaged Seafood' 'Office & Chair Mats'\n",
      " 'Pickled Goods' 'Outdoor Recreation' 'Indoor Games' 'Arts & Crafts'\n",
      " 'À La Carte Item' 'Frozen Appetizers' 'Food Storage' 'Tea'\n",
      " 'Vehicle Maintenance, Care & Decor' 'Games'\n",
      " 'Arcade Equipment & Accessories' 'Baby Toys & Activity Equipment'\n",
      " 'Hard Ciders' 'Luggage Accessories' 'Lawn & Garden' 'Books' 'Condiments'\n",
      " 'Lighting' 'Ice' 'Presentation Supplies' 'Handbag, Wallet & Accessories'\n",
      " 'Emergency Preparedness' 'Music & Recordings' 'Party & Celebration'\n",
      " 'Shoes' 'Pool, Spa & Accessories' 'Baby & Toddler Feeding'\n",
      " 'Malt Beverages' 'Household Appliances' 'Shipping Supplies'\n",
      " 'Frozen Sides' 'Baby Transport']\n",
      "\n",
      "Unique Values in CATEGORY_3 Before Standardization:\n",
      "['Conductivity Gels & Lotions' 'Cheese Curls & Puffs'\n",
      " 'Hair Care Accessories' 'Toothpaste' 'Essential Oils'\n",
      " 'Vitamins & Herbal Supplements' \"Men's Deodorant & Antiperspirant\"\n",
      " 'Granola Bars' 'Skin Treatments' 'Hand & Body Lotions' 'Hazelnuts'\n",
      " 'Shower Caps' 'Hair Tools' 'Candy Variety Pack' 'unknown'\n",
      " 'Chocolate Candy' 'Oral Care Accessories' 'Hand Sanitizer Wipes'\n",
      " 'Shaving Gel & Cream' 'Crisps' 'Pies & Tarts Snack Cakes'\n",
      " 'Skin Care Masks & Peels' 'Lip Balms & Treatments'\n",
      " 'Anti-Aging Skin Care Kits' 'Shampoo' 'Ice Cream Sauces & Syrups'\n",
      " 'Reading Glasses' 'Popcorn' 'Dried Fruit' 'Sunscreen'\n",
      " 'Hair Styling Products' 'Almonds' 'Facial Cleansers' 'Confection Candy'\n",
      " 'Wheat Crackers' 'Hand Sanitizer' 'Potato Chips'\n",
      " 'Performance & Protein Bars' 'Jerky & Bites' 'Facial Pore Strips'\n",
      " 'Braces & Wraps' 'Body Wash' 'Body Powder' 'Bath & Body Gift Sets'\n",
      " 'Chestnuts' 'Denture Care' 'Brownie Snack Cakes' 'Bath Sponges & Loofahs'\n",
      " 'Snack Seeds' 'Foot Care Devices and Grooming Aids'\n",
      " 'Allergy & Sinus Medicines & Treatments' 'Facial Lotion & Moisturizer'\n",
      " 'Razors' 'Toothbrushes' 'Hot & Cold Compress' 'Floss'\n",
      " 'Sleeping & Snoring' 'Covered Nuts' 'Fruit & Nut Bars' 'Mints'\n",
      " 'Teeth Whitening' 'Fruit Snacks' 'Donut Snack Cakes' 'Bandages & Gauze'\n",
      " 'Insoles & Orthotics' 'Hair Color' 'Ear Plugs' 'Menstrual Care Underwear'\n",
      " 'Hair Treatments' 'Corn Chips' 'Pretzel Crisps' 'Eye Creams'\n",
      " 'Tattoo Care' 'Tortilla Chips' 'Cereal Bars & Breakfast Biscuits'\n",
      " 'Oral Pain Relief' 'Mixed Nuts' 'Medical Masks & Gloves'\n",
      " 'Liquid Hand Soap' 'Contact Lens Solution' 'Pistachios' 'Bath Additives'\n",
      " 'Hair Removal Cream' 'Conditioner' 'Hummus'\n",
      " 'Gender Neutral Deodorant & Antiperspirant'\n",
      " 'Topical & Muscular Medicines & Treatments' 'Menstrual Care Liners'\n",
      " 'Digestive Health Medicines & Treatments' 'Pork Skins' 'Eye Drops'\n",
      " 'Ranch Dip' 'Anti-Fungal Foot Care' 'Acne Treatments & Kits' 'Gum'\n",
      " 'Hair Removal Accessories' 'Bar Soap' 'Fruit Rolls & Twists'\n",
      " 'Rice Treats' 'Peanuts' 'Bath Brushes' 'Flavored Pretzels'\n",
      " 'Ointments & Liquids' 'Danishes & Puffs Snack Cakes'\n",
      " 'Adult Incontinence Underwear' 'Dried Vegetables' 'Body Oil'\n",
      " 'Callus Cushions & Paddings' 'After Shave' 'Cheese Crackers'\n",
      " 'Smoking Cessation' 'Sparkling Water' 'Menstrual Care Cups'\n",
      " 'Cough & Cold Medicines & Treatments' 'Traditional Pretzels'\n",
      " 'Facial Cleansing Kits' 'Adult Incontinence Liners' 'Bagel & Pita Chips'\n",
      " 'Mouthwash' 'Menstrual Care Treatments & Cleansers'\n",
      " 'Shampoo & Conditioner Combinations'\n",
      " 'Pain & Fever Medicines & Treatments' 'Breakfast Cereal'\n",
      " 'Dried Meat Sticks' 'Canned & Whipped Cream'\n",
      " \"Women's Deodorant & Antiperspirant\" 'Cashews' 'Dip Mixes' 'Salsa'\n",
      " 'Cakes & Truffles Snack Cakes' 'Other Crackers' 'Hair Loss Prevention'\n",
      " 'Ready-to-Eat Gelatin' 'Tampons' 'Shirts & Tops' 'Cola'\n",
      " 'Meal Replacement Bars' 'Adult Incontinence Furniture Pads'\n",
      " 'Adult Incontinence Bladder Supports' 'Menstrual Care Pads' 'Other Dips'\n",
      " 'Animal Crackers' 'Shampoo & Conditioner Co-Pack' 'Sandwich Crackers'\n",
      " 'Ear Drops' 'Thermometers & Accesories' 'Dry Shampoo'\n",
      " 'Adult Incontinence Pads' 'Other Nuts' 'Corn & Rice Cakes'\n",
      " 'Ready-to-Eat Pudding' 'Waxing & Strips' 'Chews & Gels'\n",
      " 'Covered Pretzels' 'Contraceptives' 'Asthma Treatments' 'First Aid Kits'\n",
      " 'Soda' 'Petroleum Jelly' 'Graham Crackers' 'Guacamole' 'Cotton Swabs'\n",
      " 'Whole Grain Chips' 'Lice Treatment' 'Saltine Crackers'\n",
      " 'Muffin Snack Cakes' 'Skin Toners & Astringents'\n",
      " 'Shredded & Grated Cheese' 'Activewear' 'Shots'\n",
      " 'Food & Beverage Carriers' 'French Onion Dip' 'Wart Removers'\n",
      " 'Skin Insect Repellent' 'Cheese Dip' 'Bean Dip' 'Butter Crackers'\n",
      " 'Ice Cream Cones' 'Sliced Cheese' 'Breath Strips & Sprays'\n",
      " 'Powdered Hand Soap' 'Sparkling Wines' 'Mushrooms' 'Jock Itch'\n",
      " 'Household Cleaning Products' 'Hard Seltzer & Still Water' 'Lager'\n",
      " 'Cheese Snacks' 'Filled Pretzels' 'Eyeglass Cleaning Kits'\n",
      " 'Cheese Blocks' 'Fresh Fish' 'Microwavable Sides' 'Prepared Snack Pack'\n",
      " 'Sleepwear & Loungewear' 'Red Wine' 'White Wine' 'Sweaters & Sweatshirts'\n",
      " 'Watches & Accessories' 'Vibration Exercise Machines'\n",
      " 'Microwavable Entrees' 'Club Soda' 'Contraceptive Cases'\n",
      " 'Prescription Lenses' 'Non-Alcoholic Beer' 'Rosé' 'Dry Pasta'\n",
      " 'Ready-to-Eat Dessert Cups' 'Kitchen Appliances'\n",
      " 'Prescription Medications' 'Packaged Pineapple' 'Fresh Grapes'\n",
      " 'Soy & Fish Sauce' 'Frozen Non-Dairy Dessert' 'Applesauce'\n",
      " 'Packaged Mixed Fruit & Cocktail' 'Packaged Pears' 'Fresh Citrus Fruits'\n",
      " 'Frozen Dairy Desserts' 'Vodka' 'Baking Ingredients' 'Gymnastics' 'Hats'\n",
      " 'Seeds & Bulbs' 'Packaged Peaches' 'Ale' 'Non-Alchoholic Cocktail Mixers'\n",
      " 'Underwear & Socks' 'Scarves & Shawls' 'Purified Water'\n",
      " 'Stovetop & Oven Entrees' 'Teriyaki Sauce' 'Frozen Pizza Rolls'\n",
      " 'Tableware' 'Jellies, Jams, & Preserves' 'Ready-To-Drink Coffee'\n",
      " 'Coconut Water' 'Granola' 'Bottoms' 'Audio Players & Recorders'\n",
      " 'Aquariums & Accessories' 'Lip Makeup' 'Stopwatches'\n",
      " 'Cream Cheese & Spreads' 'Pasta Sauce' 'Baby & Toddler Clothing'\n",
      " 'Outerwear' 'Soccer' 'Hardware Accessories' 'Peanut Butter' 'Grape Juice'\n",
      " 'Clocks' 'Cranberry Juice' 'Sparkling Fruit Juice' 'Fresh Shellfish'\n",
      " 'Play Vehicles' 'AV Carts' 'Toy Gift Baskets' 'Barware' 'Frozen Seafood'\n",
      " 'Fresh Cauliflower' 'Fresh Peppers' 'Toaster Pastries' 'Yoga & Pilates'\n",
      " 'Broth, Bouillon, & Stock' 'Non-Dairy Cheese' 'Coffee Pods'\n",
      " 'Packaged Salmon' 'Sushi' 'Chair Mats' 'Packaged Tuna' 'Vegetable Medley'\n",
      " 'Pickles' 'Oatmeal & Hot Cereal' 'Dolls, Playsets & Toy Figures'\n",
      " 'Camping & Hiking' 'Bowling' 'Sugars & Sweeteners' 'Spices & Seasonings'\n",
      " 'Art & Crafting Materials' 'Fresh Cherries' 'Flameless Candles' 'Cereal'\n",
      " 'Frozen Other Appetizers' 'Food Storage Containers' 'Iced Teas'\n",
      " 'Vehicle Fluids' 'Prepared Cocktails' 'Cookware & Bakeware' 'Clock Parts'\n",
      " 'Milk' 'Kitchen Tools & Utensils' 'Corn' 'Slot Machines' 'Throwing Darts'\n",
      " 'Baby Activity Toys' 'Weighted Clothing' 'Sunglasses' 'Outdoor Living'\n",
      " 'Fuel Containers & Tanks' 'Beans' 'Lemonade & Limeade' 'Tonic Water'\n",
      " 'Chair & Sofa Cushions' 'Seasonal & Holiday Decorations'\n",
      " 'Beer Variety Packs' 'Decorative Trays' 'Wind-Up Toys' 'Cocktail Sauces'\n",
      " 'Fresh Asparagus' 'Orange Juice' 'Flood & Spot Lights' 'Chalkboards'\n",
      " 'Hot Sauce' 'Emergency Tools & Kits' 'Snow Removal' 'Maternity Clothing'\n",
      " 'Oils & Sprays' 'Crumbled Cheese' 'Dessert Dips' 'Packaged Cherries'\n",
      " 'Fresh Melons' 'Tomato Juice' 'Sours & Fruit Beer' 'Carrots'\n",
      " 'Gift Giving' 'Potatoes' 'Baby Food Prep & Accessories'\n",
      " 'Decorative Plaques' 'Lemon & Lime Juice' 'Novelty Signs' 'Peas'\n",
      " 'Hard Sodas' 'Climate Control Appliances' 'Cycling' 'Non-Dairy Cream'\n",
      " 'Headwear & Accessories' 'Hoisin' 'Moving & Shipping Boxes'\n",
      " 'Peanut Butter Alternatives' 'Frozen French Fries' 'Baby Carriers']\n",
      "\n",
      "Final Unique Values in CATEGORY_3 After Standardization:\n",
      "['Conductivity Gels & Lotions' 'Cheese Curls & Puffs'\n",
      " 'Hair Care Accessories' 'Toothpaste' 'Essential Oils'\n",
      " 'Vitamins & Herbal Supplements' \"Men'S Deodorant & Antiperspirant\"\n",
      " 'Granola Bars' 'Skin Treatments' 'Hand & Body Lotions' 'Hazelnuts'\n",
      " 'Shower Caps' 'Hair Tools' 'Candy Variety Pack' 'Unknown'\n",
      " 'Chocolate Candy' 'Oral Care Accessories' 'Hand Sanitizer Wipes'\n",
      " 'Shaving Gel & Cream' 'Crisps' 'Pies & Tarts Snack Cakes'\n",
      " 'Skin Care Masks & Peels' 'Lip Balms & Treatments'\n",
      " 'Anti-Aging Skin Care Kits' 'Shampoo' 'Ice Cream Sauces & Syrups'\n",
      " 'Reading Glasses' 'Popcorn' 'Dried Fruit' 'Sunscreen'\n",
      " 'Hair Styling Products' 'Almonds' 'Facial Cleansers' 'Confection Candy'\n",
      " 'Wheat Crackers' 'Hand Sanitizer' 'Potato Chips'\n",
      " 'Performance & Protein Bars' 'Jerky & Bites' 'Facial Pore Strips'\n",
      " 'Braces & Wraps' 'Body Wash' 'Body Powder' 'Bath & Body Gift Sets'\n",
      " 'Chestnuts' 'Denture Care' 'Brownie Snack Cakes' 'Bath Sponges & Loofahs'\n",
      " 'Snack Seeds' 'Foot Care Devices And Grooming Aids'\n",
      " 'Allergy & Sinus Medicines & Treatments' 'Facial Lotion & Moisturizer'\n",
      " 'Razors' 'Toothbrushes' 'Hot & Cold Compress' 'Floss'\n",
      " 'Sleeping & Snoring' 'Covered Nuts' 'Fruit & Nut Bars' 'Mints'\n",
      " 'Teeth Whitening' 'Fruit Snacks' 'Donut Snack Cakes' 'Bandages & Gauze'\n",
      " 'Insoles & Orthotics' 'Hair Color' 'Ear Plugs' 'Menstrual Care Underwear'\n",
      " 'Hair Treatments' 'Corn Chips' 'Pretzel Crisps' 'Eye Creams'\n",
      " 'Tattoo Care' 'Tortilla Chips' 'Cereal Bars & Breakfast Biscuits'\n",
      " 'Oral Pain Relief' 'Mixed Nuts' 'Medical Masks & Gloves'\n",
      " 'Liquid Hand Soap' 'Contact Lens Solution' 'Pistachios' 'Bath Additives'\n",
      " 'Hair Removal Cream' 'Conditioner' 'Hummus'\n",
      " 'Gender Neutral Deodorant & Antiperspirant'\n",
      " 'Topical & Muscular Medicines & Treatments' 'Menstrual Care Liners'\n",
      " 'Digestive Health Medicines & Treatments' 'Pork Skins' 'Eye Drops'\n",
      " 'Ranch Dip' 'Anti-Fungal Foot Care' 'Acne Treatments & Kits' 'Gum'\n",
      " 'Hair Removal Accessories' 'Bar Soap' 'Fruit Rolls & Twists'\n",
      " 'Rice Treats' 'Peanuts' 'Bath Brushes' 'Flavored Pretzels'\n",
      " 'Ointments & Liquids' 'Danishes & Puffs Snack Cakes'\n",
      " 'Adult Incontinence Underwear' 'Dried Vegetables' 'Body Oil'\n",
      " 'Callus Cushions & Paddings' 'After Shave' 'Cheese Crackers'\n",
      " 'Smoking Cessation' 'Sparkling Water' 'Menstrual Care Cups'\n",
      " 'Cough & Cold Medicines & Treatments' 'Traditional Pretzels'\n",
      " 'Facial Cleansing Kits' 'Adult Incontinence Liners' 'Bagel & Pita Chips'\n",
      " 'Mouthwash' 'Menstrual Care Treatments & Cleansers'\n",
      " 'Shampoo & Conditioner Combinations'\n",
      " 'Pain & Fever Medicines & Treatments' 'Breakfast Cereal'\n",
      " 'Dried Meat Sticks' 'Canned & Whipped Cream'\n",
      " \"Women'S Deodorant & Antiperspirant\" 'Cashews' 'Dip Mixes' 'Salsa'\n",
      " 'Cakes & Truffles Snack Cakes' 'Other Crackers' 'Hair Loss Prevention'\n",
      " 'Ready-To-Eat Gelatin' 'Tampons' 'Shirts & Tops' 'Cola'\n",
      " 'Meal Replacement Bars' 'Adult Incontinence Furniture Pads'\n",
      " 'Adult Incontinence Bladder Supports' 'Menstrual Care Pads' 'Other Dips'\n",
      " 'Animal Crackers' 'Shampoo & Conditioner Co-Pack' 'Sandwich Crackers'\n",
      " 'Ear Drops' 'Thermometers & Accesories' 'Dry Shampoo'\n",
      " 'Adult Incontinence Pads' 'Other Nuts' 'Corn & Rice Cakes'\n",
      " 'Ready-To-Eat Pudding' 'Waxing & Strips' 'Chews & Gels'\n",
      " 'Covered Pretzels' 'Contraceptives' 'Asthma Treatments' 'First Aid Kits'\n",
      " 'Soda' 'Petroleum Jelly' 'Graham Crackers' 'Guacamole' 'Cotton Swabs'\n",
      " 'Whole Grain Chips' 'Lice Treatment' 'Saltine Crackers'\n",
      " 'Muffin Snack Cakes' 'Skin Toners & Astringents'\n",
      " 'Shredded & Grated Cheese' 'Activewear' 'Shots'\n",
      " 'Food & Beverage Carriers' 'French Onion Dip' 'Wart Removers'\n",
      " 'Skin Insect Repellent' 'Cheese Dip' 'Bean Dip' 'Butter Crackers'\n",
      " 'Ice Cream Cones' 'Sliced Cheese' 'Breath Strips & Sprays'\n",
      " 'Powdered Hand Soap' 'Sparkling Wines' 'Mushrooms' 'Jock Itch'\n",
      " 'Household Cleaning Products' 'Hard Seltzer & Still Water' 'Lager'\n",
      " 'Cheese Snacks' 'Filled Pretzels' 'Eyeglass Cleaning Kits'\n",
      " 'Cheese Blocks' 'Fresh Fish' 'Microwavable Sides' 'Prepared Snack Pack'\n",
      " 'Sleepwear & Loungewear' 'Red Wine' 'White Wine' 'Sweaters & Sweatshirts'\n",
      " 'Watches & Accessories' 'Vibration Exercise Machines'\n",
      " 'Microwavable Entrees' 'Club Soda' 'Contraceptive Cases'\n",
      " 'Prescription Lenses' 'Non-Alcoholic Beer' 'Rosé' 'Dry Pasta'\n",
      " 'Ready-To-Eat Dessert Cups' 'Kitchen Appliances'\n",
      " 'Prescription Medications' 'Packaged Pineapple' 'Fresh Grapes'\n",
      " 'Soy & Fish Sauce' 'Frozen Non-Dairy Dessert' 'Applesauce'\n",
      " 'Packaged Mixed Fruit & Cocktail' 'Packaged Pears' 'Fresh Citrus Fruits'\n",
      " 'Frozen Dairy Desserts' 'Vodka' 'Baking Ingredients' 'Gymnastics' 'Hats'\n",
      " 'Seeds & Bulbs' 'Packaged Peaches' 'Ale' 'Non-Alchoholic Cocktail Mixers'\n",
      " 'Underwear & Socks' 'Scarves & Shawls' 'Purified Water'\n",
      " 'Stovetop & Oven Entrees' 'Teriyaki Sauce' 'Frozen Pizza Rolls'\n",
      " 'Tableware' 'Jellies, Jams, & Preserves' 'Ready-To-Drink Coffee'\n",
      " 'Coconut Water' 'Granola' 'Bottoms' 'Audio Players & Recorders'\n",
      " 'Aquariums & Accessories' 'Lip Makeup' 'Stopwatches'\n",
      " 'Cream Cheese & Spreads' 'Pasta Sauce' 'Baby & Toddler Clothing'\n",
      " 'Outerwear' 'Soccer' 'Hardware Accessories' 'Peanut Butter' 'Grape Juice'\n",
      " 'Clocks' 'Cranberry Juice' 'Sparkling Fruit Juice' 'Fresh Shellfish'\n",
      " 'Play Vehicles' 'Av Carts' 'Toy Gift Baskets' 'Barware' 'Frozen Seafood'\n",
      " 'Fresh Cauliflower' 'Fresh Peppers' 'Toaster Pastries' 'Yoga & Pilates'\n",
      " 'Broth, Bouillon, & Stock' 'Non-Dairy Cheese' 'Coffee Pods'\n",
      " 'Packaged Salmon' 'Sushi' 'Chair Mats' 'Packaged Tuna' 'Vegetable Medley'\n",
      " 'Pickles' 'Oatmeal & Hot Cereal' 'Dolls, Playsets & Toy Figures'\n",
      " 'Camping & Hiking' 'Bowling' 'Sugars & Sweeteners' 'Spices & Seasonings'\n",
      " 'Art & Crafting Materials' 'Fresh Cherries' 'Flameless Candles' 'Cereal'\n",
      " 'Frozen Other Appetizers' 'Food Storage Containers' 'Iced Teas'\n",
      " 'Vehicle Fluids' 'Prepared Cocktails' 'Cookware & Bakeware' 'Clock Parts'\n",
      " 'Milk' 'Kitchen Tools & Utensils' 'Corn' 'Slot Machines' 'Throwing Darts'\n",
      " 'Baby Activity Toys' 'Weighted Clothing' 'Sunglasses' 'Outdoor Living'\n",
      " 'Fuel Containers & Tanks' 'Beans' 'Lemonade & Limeade' 'Tonic Water'\n",
      " 'Chair & Sofa Cushions' 'Seasonal & Holiday Decorations'\n",
      " 'Beer Variety Packs' 'Decorative Trays' 'Wind-Up Toys' 'Cocktail Sauces'\n",
      " 'Fresh Asparagus' 'Orange Juice' 'Flood & Spot Lights' 'Chalkboards'\n",
      " 'Hot Sauce' 'Emergency Tools & Kits' 'Snow Removal' 'Maternity Clothing'\n",
      " 'Oils & Sprays' 'Crumbled Cheese' 'Dessert Dips' 'Packaged Cherries'\n",
      " 'Fresh Melons' 'Tomato Juice' 'Sours & Fruit Beer' 'Carrots'\n",
      " 'Gift Giving' 'Potatoes' 'Baby Food Prep & Accessories'\n",
      " 'Decorative Plaques' 'Lemon & Lime Juice' 'Novelty Signs' 'Peas'\n",
      " 'Hard Sodas' 'Climate Control Appliances' 'Cycling' 'Non-Dairy Cream'\n",
      " 'Headwear & Accessories' 'Hoisin' 'Moving & Shipping Boxes'\n",
      " 'Peanut Butter Alternatives' 'Frozen French Fries' 'Baby Carriers']\n",
      "\n",
      "Unique Values in CATEGORY_4 Before Standardization:\n",
      "['unknown' 'Hair Brushes & Combs' \"Women's Shaving Gel & Cream\"\n",
      " 'Lip Balms' 'Already Popped Popcorn' \"Men's Razors\" 'Snoring Aids'\n",
      " 'Popcorn Kernels & Popcorn Seasonings' 'Sleep Aids' 'Hair Straighteners'\n",
      " 'Medicated Lip Treatments'\n",
      " 'Nausea & Motion Sickness Medicines & Treatments' \"Women's Razors\"\n",
      " 'Flavored Sparkling Water' 'Immune Support'\n",
      " 'Constipation Relief Medicines & Treatments'\n",
      " 'Cold & Flu Medicines & Treatments'\n",
      " 'Anti Diarrheal Medicines & Treatments' 'Cough Drops & Lozenges'\n",
      " 'Water Pills' 'Microwave Popcorn'\n",
      " 'Cough & Chest Congestion Medicines & Treatments'\n",
      " 'Heartburn & Antacids Medicines & Treatments' 'Regular Cola' 'Diet Cola'\n",
      " 'Sore Throat Medicines & Treatments' 'Gas Relief Medicines & Treatments'\n",
      " 'Diet Soda' 'Vapors & Rubs' \"Men's Shaving Gel & Cream\" 'Skin Toners'\n",
      " 'Lactose Intolerance Medicines & Treatments' 'Water Bottles'\n",
      " 'Unflavored Sparkling Water' 'Hair Dryers' 'Orange Soda'\n",
      " 'Gender Neutral Razors' 'Ginger Ale' 'Natural Sliced Cheese'\n",
      " 'Sparkling Wine' 'Oven & Grill Cleaners' 'American Lager'\n",
      " 'Individually Packaged Cheese Snacks' 'Astringents' 'Imported Lager'\n",
      " 'Zero Sugar Cola' 'Lemon-Lime Soda' 'Microwavable Non-Potato Sides'\n",
      " 'Red Blend' 'Pinot Gris & Pinot Grigio' 'Pre-Cut Cheese Snacks'\n",
      " 'Rosé & Blends' 'Gender Neutral Shaving Gel & Cream' 'White Moscato'\n",
      " 'Refrigerators' 'Chardonnay' 'Sherbet' 'Syrah/Shiraz' 'Ice Cream'\n",
      " 'Pie Crust & Pie Filling' 'Drink Sleeves' 'Root Beer' 'White Zinfandel'\n",
      " 'Stout Ale' 'Margarita Mix' 'Underwear' 'Riesling'\n",
      " 'Purified Unflavored Water' 'Stovetop Macaroni & Cheese' 'Other Whites'\n",
      " 'Other Non-Alchoholic Cocktail Mixers' 'Drinkware' 'Cabernet Sauvignon'\n",
      " 'Other Red Wines' 'Lip Gloss' 'Cheese Spreads' 'Red Pasta Sauce'\n",
      " 'Baby & Toddler Tops' 'Tops' 'Purified Flavored Water'\n",
      " 'Frozen Dairy Novelties' 'Tool Storage & Organization' 'Wall Clocks'\n",
      " 'Grape Soda' 'Bottle Caps' 'Frozen Fish Fillets' 'Socks' 'White Blend'\n",
      " 'Yoga & Pilates Mats' 'Coolers' 'Merlot' 'Specialty & Cream Sodas'\n",
      " 'Frozen Shellfish' 'Pinot Noir' 'Corn Syrup' 'White Merlot'\n",
      " 'Breadcrumbs & Coatings' 'Craft Paint, Ink & Glaze' 'Prosecco'\n",
      " 'Baby & Toddler Socks & Tights' 'Meal Kits' 'Zinfandel' 'Champagne'\n",
      " 'Cookware' 'Coconut Milk' 'Pancake & Waffle Syrup' 'Kitchen Organizers'\n",
      " 'Textiles' 'Ramen & Instant Noodles' 'Honey' 'Seasoning Blends'\n",
      " 'Holiday Ornaments' 'Salt & Pepper Shakers'\n",
      " 'Garlic & Onion Spices & Seasonings' 'Chili Sauce' 'Sauvignon Blanc'\n",
      " 'Ice Scrapers & Snow Brushes' 'Other Cooking & Baking Oils' 'Wasabi'\n",
      " 'Malbec' 'Dinnerware' 'Beverage Warmers' 'Humidifiers'\n",
      " 'Replacement Drink Lids' 'Baby & Toddler Outfits' 'Variety Pack Sodas'\n",
      " 'Spices']\n",
      "\n",
      "Final Unique Values in CATEGORY_4 After Standardization:\n",
      "['Unknown' 'Hair Brushes & Combs' \"Women'S Shaving Gel & Cream\"\n",
      " 'Lip Balms' 'Already Popped Popcorn' \"Men'S Razors\" 'Snoring Aids'\n",
      " 'Popcorn Kernels & Popcorn Seasonings' 'Sleep Aids' 'Hair Straighteners'\n",
      " 'Medicated Lip Treatments'\n",
      " 'Nausea & Motion Sickness Medicines & Treatments' \"Women'S Razors\"\n",
      " 'Flavored Sparkling Water' 'Immune Support'\n",
      " 'Constipation Relief Medicines & Treatments'\n",
      " 'Cold & Flu Medicines & Treatments'\n",
      " 'Anti Diarrheal Medicines & Treatments' 'Cough Drops & Lozenges'\n",
      " 'Water Pills' 'Microwave Popcorn'\n",
      " 'Cough & Chest Congestion Medicines & Treatments'\n",
      " 'Heartburn & Antacids Medicines & Treatments' 'Regular Cola' 'Diet Cola'\n",
      " 'Sore Throat Medicines & Treatments' 'Gas Relief Medicines & Treatments'\n",
      " 'Diet Soda' 'Vapors & Rubs' \"Men'S Shaving Gel & Cream\" 'Skin Toners'\n",
      " 'Lactose Intolerance Medicines & Treatments' 'Water Bottles'\n",
      " 'Unflavored Sparkling Water' 'Hair Dryers' 'Orange Soda'\n",
      " 'Gender Neutral Razors' 'Ginger Ale' 'Natural Sliced Cheese'\n",
      " 'Sparkling Wine' 'Oven & Grill Cleaners' 'American Lager'\n",
      " 'Individually Packaged Cheese Snacks' 'Astringents' 'Imported Lager'\n",
      " 'Zero Sugar Cola' 'Lemon-Lime Soda' 'Microwavable Non-Potato Sides'\n",
      " 'Red Blend' 'Pinot Gris & Pinot Grigio' 'Pre-Cut Cheese Snacks'\n",
      " 'Rosé & Blends' 'Gender Neutral Shaving Gel & Cream' 'White Moscato'\n",
      " 'Refrigerators' 'Chardonnay' 'Sherbet' 'Syrah/Shiraz' 'Ice Cream'\n",
      " 'Pie Crust & Pie Filling' 'Drink Sleeves' 'Root Beer' 'White Zinfandel'\n",
      " 'Stout Ale' 'Margarita Mix' 'Underwear' 'Riesling'\n",
      " 'Purified Unflavored Water' 'Stovetop Macaroni & Cheese' 'Other Whites'\n",
      " 'Other Non-Alchoholic Cocktail Mixers' 'Drinkware' 'Cabernet Sauvignon'\n",
      " 'Other Red Wines' 'Lip Gloss' 'Cheese Spreads' 'Red Pasta Sauce'\n",
      " 'Baby & Toddler Tops' 'Tops' 'Purified Flavored Water'\n",
      " 'Frozen Dairy Novelties' 'Tool Storage & Organization' 'Wall Clocks'\n",
      " 'Grape Soda' 'Bottle Caps' 'Frozen Fish Fillets' 'Socks' 'White Blend'\n",
      " 'Yoga & Pilates Mats' 'Coolers' 'Merlot' 'Specialty & Cream Sodas'\n",
      " 'Frozen Shellfish' 'Pinot Noir' 'Corn Syrup' 'White Merlot'\n",
      " 'Breadcrumbs & Coatings' 'Craft Paint, Ink & Glaze' 'Prosecco'\n",
      " 'Baby & Toddler Socks & Tights' 'Meal Kits' 'Zinfandel' 'Champagne'\n",
      " 'Cookware' 'Coconut Milk' 'Pancake & Waffle Syrup' 'Kitchen Organizers'\n",
      " 'Textiles' 'Ramen & Instant Noodles' 'Honey' 'Seasoning Blends'\n",
      " 'Holiday Ornaments' 'Salt & Pepper Shakers'\n",
      " 'Garlic & Onion Spices & Seasonings' 'Chili Sauce' 'Sauvignon Blanc'\n",
      " 'Ice Scrapers & Snow Brushes' 'Other Cooking & Baking Oils' 'Wasabi'\n",
      " 'Malbec' 'Dinnerware' 'Beverage Warmers' 'Humidifiers'\n",
      " 'Replacement Drink Lids' 'Baby & Toddler Outfits' 'Variety Pack Sodas'\n",
      " 'Spices']\n"
     ]
    }
   ],
   "source": [
    "# Columns to Standardize\n",
    "category_columns = ['CATEGORY_2', 'CATEGORY_3', 'CATEGORY_4']\n",
    "\n",
    "for col in category_columns:\n",
    "    print(f\"\\nUnique Values in {col} Before Standardization:\")\n",
    "    print(products[col].unique())\n",
    "\n",
    "    # Step 1: Standardize values\n",
    "    products[col] = products[col].fillna('Unknown')  # Replace missing values with 'Unknown'\n",
    "    products[col] = products[col].str.strip()  # Remove leading/trailing spaces\n",
    "    products[col] = products[col].str.title()  # Convert to title case\n",
    "\n",
    "    # Step 2: Validate changes\n",
    "    print(f\"\\nFinal Unique Values in {col} After Standardization:\")\n",
    "    print(products[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Values in MANUFACTURER Before Cleaning:\n",
      "['unknown' 'PLACEHOLDER MANUFACTURER' 'COLGATE-PALMOLIVE' ...\n",
      " 'VIDETTE INC' 'SCRUB-IT' 'OUTDOOR PRODUCT INNOVATIONS, INC.']\n",
      "\n",
      "Final Unique Values in MANUFACTURER After Cleaning and Standardization:\n",
      "['Unknown' 'Placeholder Manufacturer' 'Colgate-Palmolive' ...\n",
      " 'Vidette Inc' 'Scrub-It' 'Outdoor Product Innovations, Inc.']\n",
      "\n",
      "Unique Values in BRAND Before Cleaning:\n",
      "['unknown' 'ELECSOP' 'COLGATE' ... 'SHULEMIN' 'RHINO BLINDS' 'GATEWAY']\n",
      "\n",
      "Final Unique Values in BRAND After Cleaning and Standardization:\n",
      "['Unknown' 'Elecsop' 'Colgate' ... 'Shulemin' 'Rhino Blinds' 'Gateway']\n"
     ]
    }
   ],
   "source": [
    "# Cleaning and Standardizing Textual Columns (MANUFACTURER and BRAND)\n",
    "\n",
    "# Assumptions:\n",
    "# 1. Missing values in MANUFACTURER and BRAND are replaced with 'Unknown' as they might represent incomplete data.\n",
    "# 2. Text data is standardized to remove inconsistencies caused by leading/trailing spaces or inconsistent casing.\n",
    "\n",
    "# Columns to clean\n",
    "textual_columns = ['MANUFACTURER', 'BRAND']\n",
    "\n",
    "for col in textual_columns:\n",
    "    # Show unique values before cleaning\n",
    "    print(f\"\\nUnique Values in {col} Before Cleaning:\")\n",
    "    print(products[col].unique())\n",
    "    \n",
    "    # Step 1: Replace missing values with 'Unknown'\n",
    "    # This ensures no rows have missing data for these critical columns.\n",
    "    products[col] = products[col].fillna('Unknown')\n",
    "\n",
    "    # Step 2: Standardize textual data\n",
    "    # Strip any leading/trailing spaces and convert to title case for uniformity.\n",
    "    products[col] = products[col].str.strip()  # Remove extra spaces\n",
    "    products[col] = products[col].str.title()  # Convert to title case (e.g., 'abc' -> 'Abc')\n",
    "\n",
    "    # Validate results after cleaning\n",
    "    print(f\"\\nFinal Unique Values in {col} After Cleaning and Standardization:\")\n",
    "    print(products[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 841342 entries, 0 to 845551\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   CATEGORY_1    841342 non-null  object \n",
      " 1   CATEGORY_2    841342 non-null  object \n",
      " 2   CATEGORY_3    841342 non-null  object \n",
      " 3   CATEGORY_4    841342 non-null  object \n",
      " 4   MANUFACTURER  841342 non-null  object \n",
      " 5   BRAND         841342 non-null  object \n",
      " 6   BARCODE       841342 non-null  float64\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 51.4+ MB\n",
      "\n",
      "Data Types After Validation:\n",
      "CATEGORY_1       object\n",
      "CATEGORY_2       object\n",
      "CATEGORY_3       object\n",
      "CATEGORY_4       object\n",
      "MANUFACTURER     object\n",
      "BRAND            object\n",
      "BARCODE         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "products.info()\n",
    "\n",
    "# Step 4: Confirm data types\n",
    "print(\"\\nData Types After Validation:\")\n",
    "print(products.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Verification of PRODUCTS_TAKEHOME Dataset\n",
    "# Assumptions:\n",
    "# - The BARCODE column is critical for product identification, so all duplicates and missing values must be resolved.\n",
    "# - No null values should remain in the dataset after cleaning.\n",
    "\n",
    "# Findings:\n",
    "# - All missing values in categorical columns (CATEGORY_1, CATEGORY_2, etc.) were replaced with 'UNKNOWN'.\n",
    "# - All duplicate BARCODEs were removed, retaining the first occurrence.\n",
    "# - Final verification shows no remaining missing values or duplicate BARCODEs.\n",
    "\n",
    "# Action Taken:\n",
    "# - Verified that the dataset is now clean and ready for further analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading TRANSACTION_TAKEHOME Dataset for Cleaning and Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of TRANSACTION_TAKEHOME Dataset:\n",
      "                             RECEIPT_ID PURCHASE_DATE  \\\n",
      "0  0000d256-4041-4a3e-adc4-5623fb6e0c99    2024-08-21   \n",
      "1  0001455d-7a92-4a7b-a1d2-c747af1c8fd3    2024-07-20   \n",
      "2  00017e0a-7851-42fb-bfab-0baa96e23586    2024-08-18   \n",
      "3  000239aa-3478-453d-801e-66a82e39c8af    2024-06-18   \n",
      "4  00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1    2024-07-04   \n",
      "\n",
      "                   SCAN_DATE STORE_NAME                   USER_ID  \\\n",
      "0  2024-08-21 14:19:06.539 Z    WALMART  63b73a7f3d310dceeabd4758   \n",
      "1  2024-07-20 09:50:24.206 Z       ALDI  62c08877baa38d1a1f6c211a   \n",
      "2  2024-08-19 15:38:56.813 Z    WALMART  60842f207ac8b7729e472020   \n",
      "3  2024-06-19 11:03:37.468 Z  FOOD LION  63fcd7cea4f8442c3386b589   \n",
      "4  2024-07-05 15:56:43.549 Z   RANDALLS  6193231ae9b3d75037b0f928   \n",
      "\n",
      "        BARCODE FINAL_QUANTITY FINAL_SALE  \n",
      "0  1.530001e+10           1.00             \n",
      "1           NaN           zero       1.49  \n",
      "2  7.874223e+10           1.00             \n",
      "3  7.833997e+11           zero       3.49  \n",
      "4  4.790050e+10           1.00             \n",
      "\n",
      "Data Types in TRANSACTION_TAKEHOME Dataset:\n",
      "RECEIPT_ID         object\n",
      "PURCHASE_DATE      object\n",
      "SCAN_DATE          object\n",
      "STORE_NAME         object\n",
      "USER_ID            object\n",
      "BARCODE           float64\n",
      "FINAL_QUANTITY     object\n",
      "FINAL_SALE         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load the TRANSACTION_TAKEHOME dataset\n",
    "transactions = pd.read_csv('TRANSACTION_TAKEHOME.csv')\n",
    "\n",
    "# Preview the dataset\n",
    "print(\"\\nPreview of TRANSACTION_TAKEHOME Dataset:\")\n",
    "print(transactions.head())\n",
    "\n",
    "# Display column data types\n",
    "print(\"\\nData Types in TRANSACTION_TAKEHOME Dataset:\")\n",
    "print(transactions.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in TRANSACTION_TAKEHOME Dataset:\n",
      "RECEIPT_ID           0\n",
      "PURCHASE_DATE        0\n",
      "SCAN_DATE            0\n",
      "STORE_NAME           0\n",
      "USER_ID              0\n",
      "BARCODE           5762\n",
      "FINAL_QUANTITY       0\n",
      "FINAL_SALE           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check for missing values\n",
    "missing_values_transactions = transactions.isnull().sum()\n",
    "print(\"\\nMissing Values in TRANSACTION_TAKEHOME Dataset:\")\n",
    "print(missing_values_transactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Duplicate Rows in TRANSACTION_TAKEHOME Dataset:\n",
      "171\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check for duplicate rows\n",
    "duplicate_rows_transactions = transactions.duplicated().sum()\n",
    "print(\"\\nNumber of Duplicate Rows in TRANSACTION_TAKEHOME Dataset:\")\n",
    "print(duplicate_rows_transactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Duplicate Rows After Removal:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Remove duplicate rows\n",
    "transactions = transactions.drop_duplicates()\n",
    "\n",
    "# Confirm changes\n",
    "print(\"\\nNumber of Duplicate Rows After Removal:\")\n",
    "print(transactions.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grouped Data for Missing BARCODE Values:\n",
      "STORE_NAME\n",
      "1AINTING CUSVAL BISTRO               2\n",
      "57 BAYARD STREET                     2\n",
      "7-ELEVEN                             4\n",
      "ALDI                              2330\n",
      "ALQI                                 2\n",
      "                                  ... \n",
      "WINCO FOODS                          4\n",
      "WINN-DIXIE                          28\n",
      "WOODMAN'S MARKET                     2\n",
      "Y DULCERIA LA BONITA PALETERIA       2\n",
      "YALLAH TACO                          2\n",
      "Name: USER_ID, Length: 215, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Investigating Rows with Missing BARCODE Values\n",
    "\n",
    "# Assumptions:\n",
    "# 1. The BARCODE column is critical for identifying products in the transactions dataset.\n",
    "# 2. Rows with missing BARCODE values may indicate incomplete or invalid transaction data.\n",
    "# 3. Understanding the patterns in missing BARCODE rows (e.g., STORE_NAME and USER_ID) can help decide how to handle them.\n",
    "\n",
    "# Findings:\n",
    "# - Missing BARCODE rows will be grouped by STORE_NAME to identify patterns or trends.\n",
    "\n",
    "# Action:\n",
    "# - Identify rows where the BARCODE value is missing.\n",
    "# - Group these rows by STORE_NAME and count occurrences for each store.\n",
    "\n",
    "# Identify rows with missing BARCODE values\n",
    "missing_barcodes = transactions[transactions['BARCODE'].isnull()]\n",
    "\n",
    "# Group missing BARCODE rows by STORE_NAME and count the number of USER_IDs\n",
    "missing_barcodes_grouped = missing_barcodes.groupby(['STORE_NAME'])['USER_ID'].count()\n",
    "\n",
    "# Display results to analyze patterns in missing BARCODE data\n",
    "print(\"\\nGrouped Data for Missing BARCODE Values:\")\n",
    "print(missing_barcodes_grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Missing FINAL_SALE and FINAL_QUANTITY for Rows with Missing BARCODE:\n",
      "FINAL_SALE        0\n",
      "FINAL_QUANTITY    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Check Completeness of FINAL_SALE and FINAL_QUANTITY in Rows with Missing BARCODE\n",
    "\n",
    "# Assumptions:\n",
    "# 1. FINAL_SALE and FINAL_QUANTITY are critical columns for analyzing transaction data.\n",
    "# 2. Rows with missing BARCODE values should be evaluated to check if these columns are complete.\n",
    "# 3. Completeness of these fields will help decide if rows with missing BARCODE values can still be useful.\n",
    "\n",
    "# Findings:\n",
    "# - Missing values in FINAL_SALE or FINAL_QUANTITY might indicate incomplete transaction records.\n",
    "\n",
    "# Action:\n",
    "# - Counting missing values in FINAL_SALE and FINAL_QUANTITY for rows with missing BARCODE.\n",
    "\n",
    "# Checking for missing values in FINAL_SALE and FINAL_QUANTITY\n",
    "missing_barcodes_quality = missing_barcodes[['FINAL_SALE', 'FINAL_QUANTITY']].isnull().sum()\n",
    "\n",
    "# Display the summary of missing values in FINAL_SALE and FINAL_QUANTITY\n",
    "print(\"\\nSummary of Missing FINAL_SALE and FINAL_QUANTITY for Rows with Missing BARCODE:\")\n",
    "print(missing_barcodes_quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of BARCODE_MISSING Column:\n",
      "BARCODE_MISSING\n",
      "False    44094\n",
      "True      5735\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Flag Rows with Missing BARCODE Values\n",
    "\n",
    "# Assumptions:\n",
    "# - Missing BARCODE values do not mean invalid rows but may indicate incomplete data collection.\n",
    "# - Since FINAL_SALE and FINAL_QUANTITY are valid for these rows, they still offer valuable insights.\n",
    "\n",
    "# Findings:\n",
    "# - There are 5,762 rows with missing BARCODE values.\n",
    "# - Stores like ALDI contribute significantly to these missing values (e.g., 2,330 rows).\n",
    "# - All rows with missing BARCODE values have valid FINAL_SALE and FINAL_QUANTITY data.\n",
    "\n",
    "# Decision:\n",
    "# - Retaining rows with missing BARCODE values to preserve useful information.\n",
    "# - Adding a new column, BARCODE_MISSING, to flag and track these rows during analysis will help.\n",
    "\n",
    "# Create a flag for missing BARCODE values\n",
    "transactions['BARCODE_MISSING'] = transactions['BARCODE'].isnull()\n",
    "\n",
    "# Verify the BARCODE_MISSING column by counting True and False values\n",
    "barcode_missing_summary = transactions['BARCODE_MISSING'].value_counts()\n",
    "\n",
    "# Output the summary to confirm implementation\n",
    "print(\"\\nSummary of BARCODE_MISSING Column:\")\n",
    "print(barcode_missing_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validating PURCHASE_DATE and SCAN_DATE Columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Types After Transformation:\n",
      "RECEIPT_ID                 object\n",
      "PURCHASE_DATE      datetime64[ns]\n",
      "SCAN_DATE          datetime64[ns]\n",
      "STORE_NAME                 object\n",
      "USER_ID                    object\n",
      "BARCODE                   float64\n",
      "FINAL_QUANTITY             object\n",
      "FINAL_SALE                 object\n",
      "BARCODE_MISSING              bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Step 6.1: Convert PURCHASE_DATE and SCAN_DATE to datetime format\n",
    "transactions['PURCHASE_DATE'] = pd.to_datetime(transactions['PURCHASE_DATE'], errors='coerce')\n",
    "transactions['SCAN_DATE'] = pd.to_datetime(transactions['SCAN_DATE'].str[:-2], errors='coerce')  # Remove timezone info if present\n",
    "\n",
    "# Confirm changes\n",
    "print(\"\\nData Types After Transformation:\")\n",
    "print(transactions.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Rows Where PURCHASE_DATE > SCAN_DATE: 94\n",
      "\n",
      "Sample of Rows with Invalid Dates:\n",
      "                               RECEIPT_ID PURCHASE_DATE  \\\n",
      "51   008c1dcc-0f96-4b04-98c8-2a2bb63ef89d    2024-07-21   \n",
      "455  04a320ed-2903-45e5-8fd7-6eaf08daef32    2024-06-29   \n",
      "494  05023b3d-5f83-47a7-a17c-8e8521d0bc94    2024-09-08   \n",
      "675  06ce3da3-a588-4c37-93b4-0b6d11e42704    2024-06-22   \n",
      "870  08d0e78f-3e63-40a3-8eb0-73fdf76da52c    2024-06-22   \n",
      "\n",
      "                  SCAN_DATE            STORE_NAME                   USER_ID  \\\n",
      "51  2024-07-20 19:54:23.133               WALMART  5dc24cdb682fcf1229d04bd6   \n",
      "455 2024-06-28 11:03:31.783  DOLLAR GENERAL STORE  62855f67708670299a658035   \n",
      "494 2024-09-07 22:22:29.903             SHOP RITE  666a43c77c0469953bfd9ae0   \n",
      "675 2024-06-21 12:34:15.665              BIG LOTS  646f6ffb7a342372c858487e   \n",
      "870 2024-06-21 20:50:01.298  DOLLAR GENERAL STORE  664cafb6e04f743a096a837e   \n",
      "\n",
      "          BARCODE FINAL_QUANTITY FINAL_SALE  BARCODE_MISSING  \n",
      "51   6.811312e+11           zero       3.18            False  \n",
      "455  4.900002e+10           zero       6.00            False  \n",
      "494  6.414404e+10           2.00                       False  \n",
      "675  3.111117e+11           zero       4.05            False  \n",
      "870  7.680828e+10           2.00                       False  \n"
     ]
    }
   ],
   "source": [
    "# Step 6.2: Identify Rows Where PURCHASE_DATE > SCAN_DATE\n",
    "\n",
    "# Assumptions:\n",
    "# - The PURCHASE_DATE should be on or before the SCAN_DATE, as a receipt is scanned after the purchase.\n",
    "# - Rows with PURCHASE_DATE > SCAN_DATE indicate invalid or inconsistent data.\n",
    "\n",
    "# Findings:\n",
    "# - Rows with this issue need to be identified and reviewed for potential correction or exclusion.\n",
    "\n",
    "# Action:\n",
    "# - Identifying rows where PURCHASE_DATE is later than SCAN_DATE.\n",
    "# - Counting the number of such invalid rows and displaying a sample for further analysis.\n",
    "\n",
    "# Identify rows where PURCHASE_DATE is greater than SCAN_DATE\n",
    "invalid_date_rows = transactions[transactions['PURCHASE_DATE'] > transactions['SCAN_DATE']]\n",
    "\n",
    "# Count and display the invalid rows\n",
    "invalid_date_count = invalid_date_rows.shape[0]\n",
    "invalid_date_rows_sample = invalid_date_rows.head()\n",
    "\n",
    "# Display the results\n",
    "print(f\"\\nNumber of Rows Where PURCHASE_DATE > SCAN_DATE: {invalid_date_count}\")\n",
    "print(\"\\nSample of Rows with Invalid Dates:\")\n",
    "print(invalid_date_rows_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Remaining Rows Where PURCHASE_DATE > SCAN_DATE: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 6.3: Correcting Invalid SCAN_DATE by Setting It Equal to PURCHASE_DATE\n",
    "\n",
    "# Assumptions:\n",
    "# - Rows where PURCHASE_DATE > SCAN_DATE are considered invalid due to logical inconsistency.\n",
    "# - To correct this, the SCAN_DATE will be set equal to PURCHASE_DATE, assuming scanning occurred on the same day as purchase.\n",
    "\n",
    "# Findings:\n",
    "# - Correcting these invalid rows ensures consistency in the dataset.\n",
    "\n",
    "# Action:\n",
    "# - Updating SCAN_DATE to match PURCHASE_DATE for rows where PURCHASE_DATE > SCAN_DATE.\n",
    "# - Later, \n",
    "\n",
    "# Correct SCAN_DATE for invalid rows\n",
    "transactions.loc[transactions['PURCHASE_DATE'] > transactions['SCAN_DATE'], 'SCAN_DATE'] = transactions['PURCHASE_DATE']\n",
    "\n",
    "# Verify no invalid rows are remained.\n",
    "remaining_invalid_dates = transactions[transactions['PURCHASE_DATE'] > transactions['SCAN_DATE']].shape[0]\n",
    "\n",
    "# Output the count of remaining invalid date rows to confirm correction\n",
    "print(f\"\\nNumber of Remaining Rows Where PURCHASE_DATE > SCAN_DATE: {remaining_invalid_dates}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation of FINAL_QUANTITY and FINAL_SALE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average SALE_TO_QUANTITY Ratio Used for Imputation: 4.3356345942553105\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Impute Missing FINAL_SALE Values Using Average Ratio of SALE_TO_QUANTITY\n",
    "\n",
    "# Assumptions:\n",
    "# - FINAL_SALE and FINAL_QUANTITY are crucial for understanding transactions.\n",
    "# - Converting them to numeric ensures consistent calculations.\n",
    "# - The ratio of FINAL_SALE to FINAL_QUANTITY can be used to impute missing FINAL_SALE values.\n",
    "# - Using rows with valid BARCODE, FINAL_SALE, and FINAL_QUANTITY ensures the ratio is reliable.\n",
    "\n",
    "# Findings:\n",
    "# - Some FINAL_SALE values are missing but can be estimated using the average SALE_TO_QUANTITY ratio.\n",
    "# - The average ratio is calculated only from rows with valid data.\n",
    "\n",
    "# Action:\n",
    "# 1. Converting FINAL_SALE and FINAL_QUANTITY to numeric.\n",
    "# 2. Computing the ratio (FINAL_SALE / FINAL_QUANTITY) for valid rows.\n",
    "# 3. Calculating the average ratio from valid rows.\n",
    "# 4. Using the average ratio to impute missing FINAL_SALE values.\n",
    "\n",
    "# Step 7.1: Convert FINAL_QUANTITY and FINAL_SALE to numeric\n",
    "transactions['FINAL_QUANTITY'] = pd.to_numeric(transactions['FINAL_QUANTITY'], errors='coerce')\n",
    "transactions['FINAL_SALE'] = pd.to_numeric(transactions['FINAL_SALE'], errors='coerce')\n",
    "\n",
    "# Step 7.2: Compute valid ratio (FINAL_SALE / FINAL_QUANTITY) for rows with BARCODE\n",
    "valid_rows = transactions[\n",
    "    (transactions['BARCODE'].notnull()) &  # BARCODE must be valid\n",
    "    (transactions['FINAL_SALE'].notnull()) &  # FINAL_SALE must not be missing\n",
    "    (transactions['FINAL_QUANTITY'] > 0)  # FINAL_QUANTITY must be greater than zero\n",
    "].copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "# Add a new column for the ratio\n",
    "valid_rows['SALE_TO_QUANTITY_RATIO'] = valid_rows['FINAL_SALE'] / valid_rows['FINAL_QUANTITY']\n",
    "\n",
    "# Step 7.3: Calculate the average ratio\n",
    "average_ratio = valid_rows['SALE_TO_QUANTITY_RATIO'].mean()\n",
    "\n",
    "# Step 7.4: Impute missing FINAL_SALE values using the average ratio\n",
    "transactions.loc[transactions['FINAL_SALE'].isnull(), 'FINAL_SALE'] = (\n",
    "    transactions['FINAL_QUANTITY'] * average_ratio\n",
    ")\n",
    "\n",
    "# Display the average ratio for verification\n",
    "print(f\"\\nAverage SALE_TO_QUANTITY Ratio Used for Imputation: {average_ratio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Remaining Missing Values in FINAL_SALE: 0\n",
      "\n",
      "Sample of Rows with Imputed FINAL_SALE Values:\n",
      "                                 RECEIPT_ID PURCHASE_DATE  \\\n",
      "49990  441b9ecd-38ed-4960-9780-eb44a464284a    2024-06-26   \n",
      "49991  840c30ae-bc0a-40a4-a47d-052ed0af2da2    2024-08-18   \n",
      "49992  68f74fb3-ccf2-41f3-896a-799eb9a80680    2024-08-13   \n",
      "49993  f6d3e61d-488d-448b-8148-8d681e55b3d2    2024-09-01   \n",
      "49994  6cdf3c1a-78b3-4fb0-85fd-52e2f5b4731c    2024-06-26   \n",
      "49995  b5cd61a9-8033-4913-a5c4-fb3f65e3a321    2024-08-21   \n",
      "49996  e1b2f634-c9ad-4152-b662-4b22efc25862    2024-08-11   \n",
      "49997  b07ef8dd-e444-40a2-819b-f74a3e5f1ae7    2024-07-11   \n",
      "49998  42475141-bef4-4df2-aa37-72577e2512bb    2024-06-18   \n",
      "49999  3a179c4e-46f2-4126-b3d2-3514afc23a3e    2024-08-07   \n",
      "\n",
      "                    SCAN_DATE        STORE_NAME                   USER_ID  \\\n",
      "49990 2024-07-02 09:37:07.656  FRY'S FOOD STORE  6251c788e3d6762c55855c1d   \n",
      "49991 2024-08-18 14:44:02.530            COSTCO  65b322787050d0a6206b3479   \n",
      "49992 2024-08-19 11:06:59.023   PEPPERIDGE FARM  64f4aee2b84ba41db3fb246a   \n",
      "49993 2024-09-06 08:03:54.617            TARGET  61056fcc1efef449f0f39f7c   \n",
      "49994 2024-07-01 11:00:39.769     HARRIS TEETER  5de7ec93ca63cc17893cdd14   \n",
      "49995 2024-08-31 14:13:08.634            TARGET  6154bcf098f885648de2f299   \n",
      "49996 2024-08-11 18:15:56.736       STOP & SHOP  60aa809f188b926b2244c974   \n",
      "49997 2024-07-11 08:03:25.816           WALMART  60bd26e83dc3b13a15c5f4e7   \n",
      "49998 2024-06-18 19:57:32.211     MARKET BASKET  6169912fac47744405af62b7   \n",
      "49999 2024-08-07 15:30:07.911           WALMART  64e94d64ca929250373ef6e1   \n",
      "\n",
      "            BARCODE  FINAL_QUANTITY  FINAL_SALE  BARCODE_MISSING  \n",
      "49990  7.225002e+10             1.0        2.49            False  \n",
      "49991  1.407435e+07             1.0       11.99            False  \n",
      "49992  1.410007e+10             1.0        2.89            False  \n",
      "49993  8.523904e+10             1.0        3.46            False  \n",
      "49994           NaN             1.0        3.00             True  \n",
      "49995  8.523911e+10             2.0        1.18            False  \n",
      "49996  4.610040e+10             1.0        2.00            False  \n",
      "49997  6.466300e+11             1.0       20.96            False  \n",
      "49998  4.180050e+10             1.0        3.00            False  \n",
      "49999  3.076607e+11             1.0        5.48            False  \n"
     ]
    }
   ],
   "source": [
    "# Step 7.5: Check if any missing values remain in FINAL_SALE\n",
    "missing_final_sale_count = transactions['FINAL_SALE'].isnull().sum()\n",
    "\n",
    "# Step 7.6: Verify a few rows with imputed values\n",
    "imputed_rows = transactions[transactions['FINAL_SALE'].isnull() == False].tail(10)\n",
    "\n",
    "# Display the results to verify\n",
    "print(f\"\\nNumber of Remaining Missing Values in FINAL_SALE: {missing_final_sale_count}\")\n",
    "print(\"\\nSample of Rows with Imputed FINAL_SALE Values:\")\n",
    "print(imputed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Remaining Zero FINAL_QUANTITY Values: 0\n",
      "\n",
      "Sample of Rows with Updated FINAL_QUANTITY Values:\n",
      "                                 RECEIPT_ID PURCHASE_DATE  \\\n",
      "49989  443b2c20-78c3-4cc5-b12d-9cdc07e8ee9d    2024-08-09   \n",
      "49990  441b9ecd-38ed-4960-9780-eb44a464284a    2024-06-26   \n",
      "49991  840c30ae-bc0a-40a4-a47d-052ed0af2da2    2024-08-18   \n",
      "49992  68f74fb3-ccf2-41f3-896a-799eb9a80680    2024-08-13   \n",
      "49993  f6d3e61d-488d-448b-8148-8d681e55b3d2    2024-09-01   \n",
      "49994  6cdf3c1a-78b3-4fb0-85fd-52e2f5b4731c    2024-06-26   \n",
      "49996  e1b2f634-c9ad-4152-b662-4b22efc25862    2024-08-11   \n",
      "49997  b07ef8dd-e444-40a2-819b-f74a3e5f1ae7    2024-07-11   \n",
      "49998  42475141-bef4-4df2-aa37-72577e2512bb    2024-06-18   \n",
      "49999  3a179c4e-46f2-4126-b3d2-3514afc23a3e    2024-08-07   \n",
      "\n",
      "                    SCAN_DATE        STORE_NAME                   USER_ID  \\\n",
      "49989 2024-08-09 15:27:12.423         SHOP RITE  61a3a94b6f1d182a23c8a255   \n",
      "49990 2024-07-02 09:37:07.656  FRY'S FOOD STORE  6251c788e3d6762c55855c1d   \n",
      "49991 2024-08-18 14:44:02.530            COSTCO  65b322787050d0a6206b3479   \n",
      "49992 2024-08-19 11:06:59.023   PEPPERIDGE FARM  64f4aee2b84ba41db3fb246a   \n",
      "49993 2024-09-06 08:03:54.617            TARGET  61056fcc1efef449f0f39f7c   \n",
      "49994 2024-07-01 11:00:39.769     HARRIS TEETER  5de7ec93ca63cc17893cdd14   \n",
      "49996 2024-08-11 18:15:56.736       STOP & SHOP  60aa809f188b926b2244c974   \n",
      "49997 2024-07-11 08:03:25.816           WALMART  60bd26e83dc3b13a15c5f4e7   \n",
      "49998 2024-06-18 19:57:32.211     MARKET BASKET  6169912fac47744405af62b7   \n",
      "49999 2024-08-07 15:30:07.911           WALMART  64e94d64ca929250373ef6e1   \n",
      "\n",
      "            BARCODE  FINAL_QUANTITY  FINAL_SALE  BARCODE_MISSING  \n",
      "49989  4.178007e+10             1.0        3.00            False  \n",
      "49990  7.225002e+10             1.0        2.49            False  \n",
      "49991  1.407435e+07             1.0       11.99            False  \n",
      "49992  1.410007e+10             1.0        2.89            False  \n",
      "49993  8.523904e+10             1.0        3.46            False  \n",
      "49994           NaN             1.0        3.00             True  \n",
      "49996  4.610040e+10             1.0        2.00            False  \n",
      "49997  6.466300e+11             1.0       20.96            False  \n",
      "49998  4.180050e+10             1.0        3.00            False  \n",
      "49999  3.076607e+11             1.0        5.48            False  \n"
     ]
    }
   ],
   "source": [
    "# Step 8: Replace Zero or Invalid FINAL_QUANTITY with 1 Where FINAL_SALE Is Valid\n",
    "\n",
    "# Assumptions:\n",
    "# - A FINAL_QUANTITY value of zero is invalid when FINAL_SALE has a valid non-null value.\n",
    "# - Setting such FINAL_QUANTITY values to 1 ensures logical consistency.\n",
    "\n",
    "# Findings:\n",
    "# - There are rows with FINAL_QUANTITY equal to zero despite having a valid FINAL_SALE value.\n",
    "# - These rows are updated for consistency.\n",
    "\n",
    "# Action:\n",
    "# 1. Identifying rows with FINAL_QUANTITY = 0 and valid FINAL_SALE value.\n",
    "# 2. Replacing such FINAL_QUANTITY = 0 with 1 for these rows.\n",
    "# 3. Verifying the updates by counting remaining zero values and reviewing updated rows.\n",
    "\n",
    "# Replace zero or invalid FINAL_QUANTITY with 1 where FINAL_SALE is valid\n",
    "transactions.loc[\n",
    "    (transactions['FINAL_QUANTITY'] == 0) & (transactions['FINAL_SALE'].notnull()), \n",
    "    'FINAL_QUANTITY'\n",
    "] = 1\n",
    "\n",
    "# Step 8.1: Check if any zero FINAL_QUANTITY values remain\n",
    "zero_quantity_count = (transactions['FINAL_QUANTITY'] == 0).sum()\n",
    "\n",
    "# Step 8.2: Verify rows where FINAL_QUANTITY was updated\n",
    "updated_quantity_rows = transactions[\n",
    "    (transactions['FINAL_QUANTITY'] == 1) & (transactions['FINAL_SALE'].notnull())\n",
    "].tail(10)\n",
    "\n",
    "# Display results for verification\n",
    "print(f\"\\nNumber of Remaining Zero FINAL_QUANTITY Values: {zero_quantity_count}\")\n",
    "print(\"\\nSample of Rows with Updated FINAL_QUANTITY Values:\")\n",
    "print(updated_quantity_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Per Critical Column:\n",
      "FINAL_SALE            0\n",
      "FINAL_QUANTITY    12491\n",
      "PURCHASE_DATE         0\n",
      "SCAN_DATE             0\n",
      "dtype: int64\n",
      "\n",
      "Number of Rows with Invalid 'SCAN_DATE' vs 'PURCHASE_DATE': 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in critical columns\n",
    "missing_values_check = transactions[['FINAL_SALE', 'FINAL_QUANTITY', 'PURCHASE_DATE', 'SCAN_DATE']].isnull().sum()\n",
    "\n",
    "# Identify rows where 'SCAN_DATE' is earlier than 'PURCHASE_DATE'\n",
    "invalid_dates_count = transactions[transactions['SCAN_DATE'] < transactions['PURCHASE_DATE']].shape[0]\n",
    "\n",
    "# Display results for further action\n",
    "print(\"Missing Values Per Critical Column:\")\n",
    "print(missing_values_check)\n",
    "print(f\"\\nNumber of Rows with Invalid 'SCAN_DATE' vs 'PURCHASE_DATE': {invalid_dates_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Missing FINAL_QUANTITY: 1424\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Impute Missing FINAL_QUANTITY Values\n",
    "\n",
    "# Assumptions:\n",
    "# - FINAL_QUANTITY should ideally match the quantity associated with the specific BARCODE.\n",
    "# - Rows with missing FINAL_QUANTITY but valid BARCODE can be filled with the average FINAL_QUANTITY for that BARCODE.\n",
    "\n",
    "# Findings:\n",
    "# - Missing FINAL_QUANTITY values are imputed based on the average quantity for the respective BARCODE.\n",
    "# - If no BARCODE is available, the row's FINAL_QUANTITY remains unchanged.\n",
    "\n",
    "# Actions:\n",
    "# 1. Calculateing the average FINAL_QUANTITY for each unique BARCODE.\n",
    "# 2. Imputing missing FINAL_QUANTITY values using the calculated average.\n",
    "\n",
    "# Calculate the average FINAL_QUANTITY per BARCODE\n",
    "average_quantity_per_barcode = transactions.groupby('BARCODE')['FINAL_QUANTITY'].mean()\n",
    "\n",
    "# Impute missing FINAL_QUANTITY based on the average for each BARCODE\n",
    "transactions['FINAL_QUANTITY'] = transactions.apply(\n",
    "    lambda row: average_quantity_per_barcode[row['BARCODE']]\n",
    "    if pd.isnull(row['FINAL_QUANTITY']) and not pd.isnull(row['BARCODE']) else row['FINAL_QUANTITY'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Verify remaining missing FINAL_QUANTITY values\n",
    "remaining_missing_quantity = transactions['FINAL_QUANTITY'].isnull().sum()\n",
    "\n",
    "# Display the number of remaining missing FINAL_QUANTITY values\n",
    "print(f\"Remaining Missing FINAL_QUANTITY: {remaining_missing_quantity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Missing FINAL_QUANTITY: 0\n"
     ]
    }
   ],
   "source": [
    "# Explicitly set missing FINAL_QUANTITY to 1\n",
    "transactions['FINAL_QUANTITY'] = transactions['FINAL_QUANTITY'].fillna(1)\n",
    "\n",
    "# Verify no remaining missing values in FINAL_QUANTITY\n",
    "remaining_missing_quantity = transactions['FINAL_QUANTITY'].isnull().sum()\n",
    "print(f\"Remaining Missing FINAL_QUANTITY: {remaining_missing_quantity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of STORE_NAME Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Values in STORE_NAME Column Before Validation:\n",
      "['WALMART' 'ALDI' 'FOOD LION' 'RANDALLS' 'TARGET' 'COSTCO'\n",
      " 'DOLLAR TREE STORES INC' 'FAMILY DOLLAR' 'KROGER' 'FOODS CO'\n",
      " 'REAES STORE' 'IGA' 'DOLLAR GENERAL STORE' 'PUBLIX' \"MACEY'S\" 'WALGREENS'\n",
      " 'CVS' 'WINCO FOODS' 'THE HOME DEPOT' 'FRED MEYER' 'MARKET BASKET'\n",
      " '7-ELEVEN' 'HOBBY LOBBY' 'GIANT EAGLE' 'HY-VEE' \"SAM'S CLUB\"\n",
      " 'WHISPERING PINES FRUIT FARMS' 'JEWEL OSCO' 'SHELL' 'NELES GRANACOT'\n",
      " \"TRADER JOE'S\" 'FIVE BELOW' 'GROCERY OUTLET BARGAIN MARKET' 'SMART SHOP'\n",
      " 'TINKEN AFB COMMIE' 'ALBERTSONS' 'LIDL' 'PHARMACY' 'WEIS' 'FASTRAC'\n",
      " 'RITE AID' 'MEIJER' 'COMMISSARY' 'FOODLAND' 'PAL CAMPO RESTAURANT'\n",
      " \"BJ'S WHOLESALE CLUB\" 'CARRS' 'SHOP RITE' 'PLAVERS CAFE LIDA'\n",
      " 'WINN-DIXIE' 'SAFEWAY' 'MI TIENDA' 'CIRCLE K' 'NUTS FACTORY 74TH'\n",
      " 'AMAZON' \"MARC'S\" 'WEGMANS' 'SCHNUCKS' 'FOOD DEPOT' 'BURGER KING' 'H-E-B'\n",
      " 'PIONEER SUPERMARKETS' 'KING SOOPERS' 'FESTIVAL FOODS' 'TJ MAXX'\n",
      " \"SMITH'S\" \"WOODMAN'S MARKET\" 'BRAVO SUPERMARKETS' 'GOMART' 'HANNAFORD'\n",
      " 'QFC' 'KWIK TRIP' 'MARKET' 'ACME' \"LOVE'S\" 'FOOD OUTLET' 'HARRIS TEETER'\n",
      " 'STAR MARKET' 'THE GIANT CO' 'GIANT FOOD' 'EXPRESS ROSES' 'PRICE CHOPPER'\n",
      " 'PAVILIONS' 'FOOD BAZAAR SUPERMARKET' 'JOHN DEERE HQ' 'FOOD CITY'\n",
      " 'RALPHS' 'PETCO' 'PONTE FRESCO' \"DILLON'S FOOD STORE\" 'PUEBLO'\n",
      " 'PICK N SAVE' 'PRESIDENTE SUPERMARKETS' 'MAIN STREET MARKET' 'FOOD FAIR'\n",
      " 'LA GLORIA SUPERMERCADO' 'FAREWAY' 'STOP & SHOP' 'FOOD 4 LESS' 'BIG LOTS'\n",
      " 'ENORTHGATE MARKET' 'YOUR DEKALB FARMERS MARKET' \"MARTIN'S SUPERMARKET\"\n",
      " 'PRIME TIME NUTRITION' 'THE FRESH MARKET' \"WITBECK'S FAMILY FOODS\"\n",
      " 'KEY FOOD FRESH' 'RIGGINS WATER WHITE MARKET'\n",
      " 'HIBACHI JAPANESE STK HOUSE' 'WAWA' 'TOPS MARKETS' 'SUNOCO'\n",
      " 'ROUSES MARKET' 'RABERS' \"REDNER'S MARKETS\" \"DAVE'S MARKETPLACE\"\n",
      " \"STEW LEONARD'S\" \"RALPH'S CAQUAS\" 'MARSHALLS' 'SUPERMERCADO TORRES'\n",
      " 'METRO MARKET' 'FOOD MAXX' \"BRAUN'S FOOD CENTER\" 'FARMERS SUPER MARKET'\n",
      " 'SUPERMAX' \"BUEHLER'S FRESH FOODS\" 'PIGGLY WIGGLY' 'SUPER SAVER'\n",
      " 'SUN MART FOODS' 'EXCHANGE' 'CUB FOODS' 'GAS N GO'\n",
      " \"JOHN'S GROCERY & HARDWARE\" \"RIESBECK'S FOOD MARKET\" \"SHAW'S\" 'GIANT'\n",
      " 'SAVE MART SUPERMARKETS' 'FLYING J' 'MC' 'GIANT FOOD STORE FUEL'\n",
      " 'PRICE CUTTER' 'COMPARE FOODS' 'STATER BROS' 'ANAZEH SANDS BILLIARDS'\n",
      " 'ULTA BEAUTY' 'SUPER 1 FOODS' 'TOM THUMB' 'SUPREMO FOOD MARKET'\n",
      " 'LA BONITA SUPERMARKETS' \"IT'SUGAR\" 'HOLIDAY MARKET' \"KING'S SUPERMARKET\"\n",
      " 'SPROUTS FARMERS MARKET' 'FOODTOWN' 'LUCKY SUPERMARKET'\n",
      " 'WHOLE FOODS MARKET' 'ZOOB ZIB THAI AUTHENTIC NOODLE BAR' 'OSCO'\n",
      " 'EL SUPER' 'SUPERMERCADOS SELECTOS' 'LOTTE PLAZA MARKET'\n",
      " 'VEGAS FOOD CENTER' 'FAIRPLAY' 'COSICO THOLESALE'\n",
      " 'INTERNATIONAL FOODMART' 'FOOD12' 'PATRICK AFB COMMISSARY' 'NI PUEBLO'\n",
      " 'SPEEDWAY' 'NORTHGATE MARKET' 'INGLES' 'STRACK & VAN TIL' 'BEL AIR'\n",
      " 'DOORDASH DELIV' 'COUNTY MARKET' \"FRY'S FOOD STORE\" 'SUPER FRESH'\n",
      " 'PAYLESS' 'SAVE A LOT' 'VONS' 'PALISADES' 'DOLLAR SAVER'\n",
      " 'MAI KET WE DO BEEF THE BEST ALBER TSONS MARKET THE BEST WE DO BEEF'\n",
      " 'JAY C FOOD STORES' 'LAZY ACRES' 'SHEETZ' \"BROOKSHIRE'S\" 'TIERMA'\n",
      " \"BASHAS'\" 'KWIK SHOP' 'ELGIN FRESH MARKET' 'RESTAURANT DEPOT'\n",
      " 'FRESCO Y MÁS' 'SMART & FINAL' 'THERRESDEROCER' 'MURPHY USA'\n",
      " \"BOYER'S  FOOD MARKET\" 'VALERO' 'CITY MARKET' 'SHOP N SAVE'\n",
      " 'CANARY ROOST' 'ME SALVE' 'KISMET BIALYS' \"MARIANO'S\" 'EXXON'\n",
      " 'AMAZONFRESH' 'COMMI5SARE' 'STAUFFERS OF KISSEL HILL'\n",
      " 'CARNICERIA POTOSINA' 'NT GIA' 'ING JEFE TACOSAR' 'KROGER FUEL'\n",
      " 'BARGAIN HUNT' 'ECONOFOODS' 'FOOD GIANT' 'PRICE UTTER' 'FIESTA MART'\n",
      " 'POPSHELF' 'NEW MORNING MARKET' 'WHOLESALE' 'LODE' '4 WAY MEAT MARKET'\n",
      " 'QUIKTRIP' 'HANCOCKS NEIGHBORHOOD MARKET' \"TEAL'S MARKET\"\n",
      " 'THE ATLANTIC HOTEL' 'KEY FOOD MARKETPLACE' 'DIERBERGS' 'PRICERITE'\n",
      " 'MODERN MARKET' 'SUPERCENTER' \"RIDLEY'S FAMILY MARKETS\" 'BELMONT MARKET'\n",
      " 'TOOU ORDG' 'COSTCO FUEL' \"BELACINO'S\" 'GRECIAN STEAKHOUSE'\n",
      " 'RRIENO SOUR A RALS LGROCERH' 'WBC HOB' 'GHUIRKS'\n",
      " \"LOWE'S HOME IMPROVEMENT\" '1AINTING CUSVAL BISTRO'\n",
      " 'SUN VALLEY FINE FOODS' 'AMVETS POST 11' 'VALLEY PHARMACY'\n",
      " 'NOB HILL FOODS' 'DOLLAD ENEROL' 'KTA SUPER STORES' 'BOJANGLES'\n",
      " \"TONY'S FRESH MARKET\" 'SEHERAL' 'BEAUTY SUPPLY' 'LA’BONNE’S MARKETS'\n",
      " 'TORT SAM TNTON COMMISSARY' 'FIVE BELOV' 'ALCT' 'MACS FRESH MARKET'\n",
      " 'SENTARA LEIGH DUTNATIENT' 'BIENVENIDOS MEXICAN RESTAURANT'\n",
      " 'RIVERVIEW FAMILY CENTER' 'ERMERCADOS SUPE MR. A PEG' 'FAST TRACK'\n",
      " 'SUPER SUPERMARKET' 'FRESH THYME MARKET' \"SLEEPERS' MARKET\" 'CENTER'\n",
      " 'SUPERMERCADOS ECONO' 'MACE YS ARKET' \"OWEN'S\" 'SALONCENTRIC'\n",
      " 'VALUEFRESH' 'CO COM' 'VALLARTA SUPERMARKETS' 'CF MARKS'\n",
      " \"CATTLEMAN'S ROADHOUSE\" 'EWAY SAR' 'AVI FOODSYSTEMS, INC.'\n",
      " 'THE FRESH GROCER' \"REASOR'S\" \"CHAPPELL'S HOMETOWN FOODS\" 'OMPE GFOODS'\n",
      " \"ANDRONICO'S COMMUNITY MARKETS\" 'RACETRAC' 'CAMIL/DOTLAR' 'ROSES'\n",
      " 'MENARDS' 'FLOWERS BAKING CO' 'NORTHWOODS WHOLESALE OUTLET' 'LEWER CSCO'\n",
      " 'DEFENSE COMMISSARY AGENCY' \"WEBSTER'S MARKETPLACE\" 'RIGGINS'\n",
      " 'MOSQUITO BOOKSLKOBUK TO GO' 'E W JAMES & SONS SUPERMARKETS'\n",
      " 'SUPERIOR GROCERS' \"CASEY'S GENERAL STORE\" 'CARDENAS'\n",
      " 'UNSHINE HSE HATH FOODS' \"KOHL'S\" \"BROULIM'S\" 'FRESH 4 LESS'\n",
      " 'MILLS FLEET FARM' 'ROCHE BROS. SUPERMARKET' 'ARMITAGE PRODUCE'\n",
      " 'OFFICE SUPPLIES DORADO SCHOOL &' \"NEEDLER'S FRESH MARKET\"\n",
      " 'GENERAL DISCOUNT' \"RALEY'S\" 'OUR PHARMACY' 'HUDSON'\n",
      " \"CASEL'S SUPERMARKET\" 'DILLONS COOC STORES' 'ESTRELLA SUPER MARKET'\n",
      " 'HOMETOWN GROCERY' 'MINT CO FO0 S' 'ASIA MARKET' \"DICK'S SPORTING GOODS\"\n",
      " \"J'S SALVAGE\" 'STAPLES' 'CREST FOODS' \"REONER'S\" 'GW SUPERMARKET'\n",
      " 'CASH WISE' 'RU' 'ROCHITA PLAZA MARK' 'LVERYONE'\n",
      " 'FORT JACKSON COMMISSARY' 'EAMTLY RESTAURANT' 'PRICELESS FOODS' 'AL'\n",
      " 'CASH SAVER' 'EATALY' \"MIKE'S DISCOUNT FOODS\" 'AMIGO'\n",
      " 'DISCOUNT DRUG MART' 'SUPER DISCOUNT TOBACCO' 'MERCHANT COU'\n",
      " \"DETWILER'S FARM MARKET\" 'FIESTA FOODS' 'BETHPAGE PHARMACY'\n",
      " 'SODLE PHARMACY' 'H MART' 'NAM DAE MUN FARMERS MARKET' \"FROOGEL'S\"\n",
      " 'THRIFTY PRODUCE & MEAT' 'RHODES FAMILY PRICE CHOPPER' 'LOWES FOODS'\n",
      " 'MARKET STREET' \"MOSER'S DISCOUNT FOODS\" 'SPARKLE MARKET'\n",
      " \"JUNGLE JIM'S INTERNATIONAL MARKET\" 'HARPS FOOD STORES' 'TOP TOMATO'\n",
      " \"FRESH N' LOW\" 'SCHEDULE & SAVE' 'SCHOFIELD BARRACKS COMMISSARY'\n",
      " 'TOTAL WINE & MORE' 'CHICK-FIL-A' 'GREAT GIANT SUPERMARKET'\n",
      " 'GERBES SUPER MARKETS' \"CROSBY'S\" 'VIET HOA INTERNATIONAL FOODS'\n",
      " 'TORO DE ORO MARKET' 'MART' 'TOTOPOS MEXICAN GRILL' 'CINEMARK THEATRES'\n",
      " 'LOS AZTECAS' 'MARKET 32' 'DSALONCENTRID' 'SHOP FAIR SUPERMARKETS'\n",
      " 'NEIGHBORHOOD DISCOUNT SUPERMARKET' 'BIG Y WORLD CLASS MARKET'\n",
      " 'C TCO LESALE WHO' \"PETE'S MARKET\" 'POULEVARU' 'C&C CANDIES' \"DODGE'S\"\n",
      " 'MD ORIENTAL MARKET' 'DRIVE-IN RESTAURANT JUSTRITE' \"TRIG'S\"\n",
      " 'JACKSONVILLE NAS COMMISSARY' \"RU'S\" 'THE OAK CUPBOARD' 'TEK MARKETS'\n",
      " \"SCHIEL'S FAMILY MARKET\" 'SHOPPERS' \"BAKER'S\"\n",
      " \"SAITO'S JAPANESE STEAKHOUSE\" 'COUNTRY MART' 'TRADE FAIR SUPERMARKET'\n",
      " 'PILOT' 'MARTINDALES NATURAL' 'MARKETPLACE FOODS' 'LUNDS & BYERLYS'\n",
      " \"WOME'S\" \"CARALUZZI'S MARKET\" 'BIG DEAL OUTLET' 'CONOCO' 'MART WALR'\n",
      " 'ROYAL FARMS' 'LIHE HORSESHOB' 'DILLONS FUEL' \"WOODMAN'S FUEL\"\n",
      " 'SUNSET FOODS' 'PATRIOT STORE' 'STOLE25' 'SUPER BRAYD'\n",
      " \"SCHNEIDER'S MARKET\" 'BROOKSHIRE BROTHERS' 'EL INDIO - MANCHESTER'\n",
      " 'H. YANIRIS' \"SON'S PARRISH\" 'FRESH FOODS' 'SELEDLOS BE TODO/AGUSTO'\n",
      " \"GERRITY'S SUPERMARKETS\" 'NELLIS AFB COMMISSARY' \"HORNBACHER'S\"\n",
      " 'COUNTRY MARKET INC.' 'YOODS CY' \"PATON'S MARKET PLACE\"\n",
      " 'APPLES GROCERY STORE' 'COMMUNITY MARKETS' \"UNCLE GIUSEPPE'S MARKETPLACE\"\n",
      " \"CONCESSI'S FURO MARKET\" \"MICHAEL'S\" 'OCRACOKE VARIETY'\n",
      " 'BOONEVILLE SHOPWISE' 'KARNS QUALITY FOODS' 'PENN SPARKLE'\n",
      " \"DE' FRESH MARKET\" 'SHOP A LOTT' 'PONTS FRESCO' 'ROYALS LIQUOR'\n",
      " 'THE TURN CLUB' 'FAMILY FARE SUPERMARKETS' 'TYNDALL AFB COMMISSARY'\n",
      " 'ST LUKES OUTPATIENT' 'RMERCADOS SUPER MRO PEOA' 'CHEVRON'\n",
      " '10BOX COST-PLUS' 'A CME DURP SUPERAK' 'DEJAN' 'FOOD KING'\n",
      " \"RIC'S FOOD CENTER\" 'NEW ASIA SUPERMARKET' 'PIER17'\n",
      " 'FINE FARE SUPERMARKET' 'KING KULLEN' \"BUDDY'S CRABHOUSE OYSTER BAR\"\n",
      " \"OZZIE'S FRESH MARKET BY FOOD UNIVERSE\" 'MARKET FRESH' 'THE BACK FORTY'\n",
      " 'FIRELAKE EXPRESS GROCERY' 'ACE HARDWARE' 'FRESHCO'\n",
      " 'HOSPITAL DRIVE PHARMACY' 'CHERRY VALLEY MARKETPLACE' 'JR FOOD'\n",
      " 'WESTERN BEEF' \"RALEY'S SERVICE CENTER AT\" 'TACO RIO' 'JCPENNEY'\n",
      " 'FOODARAMA' 'AR DISNEY WORLD.' 'SUPERMERCADO NAPO VELEZ'\n",
      " 'NAVARRO DISCOUNT PHARMACIES' 'SIESCA' 'SHOPPERS VALUE FOODS'\n",
      " 'BAPTIST HEALTH' 'HARVEYS SUPERMARKET' 'KINNEUDRUGS' 'WHITE & CASE CAFE'\n",
      " 'LA PANZA FELIZ' 'SES MOO MARKET' 'LA FRONTERA' \"IL''S WHIOLESALE CLUB\"\n",
      " 'MARATHON' 'KWIK FILL' 'KWIK STAR' 'SSARY COMMI' \"DICK'S\"\n",
      " 'CHANGSFOOD2020' 'CRE ST FOODS' 'WOODEN NICKEL'\n",
      " 'BUFORD HIGHWAY FARMERS MARKET' \"K ENT 'S MARKE\" 'HARTIG' 'NORDSTROM'\n",
      " 'FOOD ZONE' \"BRAUM'S ICE CREAM AND DAIRY STORES\" 'WWW.SHOPMAR MARVE'\n",
      " 'SPIRITS' 'FORT BUCHANAN COMMISSARY' 'HOMELAND' 'FARM FRESH' 'ALTA'\n",
      " 'FREAMEYER' 'SES 00 W MARKET' 'LEPPINKS FOOD CENTERS'\n",
      " \"SCHULTE'S FRESH FOODS\" 'LA MICHOACANA'\n",
      " 'THE S HHANT OR 2010 MMILY RN /TAVES' 'HOLIDAY STATIONSTORE' 'SHORT STOP'\n",
      " 'SAN DIEGO NB COMMISSARY' '/MART' 'BIG SAVER FOODS'\n",
      " \"GORDON'S SELECT MARKET\" 'ARIES SUPERMARKET' 'PEPPERIDGE FARM'\n",
      " 'SCOTT AFB COMMISSARY' 'FESTIT AL' \"CLULS SAM'S\" 'VENTURE FOODS'\n",
      " \"LAURA'S PHARMACY\" 'MOUNT AIN SUPER FRESH MARKET' 'FARMACIA CORCOVAPA'\n",
      " 'THE HALF WALL BEER HOUSE' \"HELEN'S OF ELLSWORTH\" 'EXPRESS LANE'\n",
      " 'TOWN & COUNTRY SUPERMARKET' 'APERMERCADOSS MRS PORQUE TU ARUS ESCOCININ'\n",
      " 'YALLAH TACO' 'SUMMA HEALTH' 'SELLERS BROS' \"BUTCHER'S BREWHUIS\" 'STORE'\n",
      " 'UNITED SUPERMARKETS' 'HARRIS TEETER FUEL' \"CHAMPAGNE'S MARCHE\"\n",
      " 'WESTERN UNION' 'THE FRIDGE' 'H.F DOLLAR & UP' 'CORRAL'\n",
      " 'CERMAK FRESH MARKET' 'AZUCAR CUBAN CUISINE' 'SE ECTOS'\n",
      " 'TROYER COUNTRY MARKET' \"WOODRUFF'S MARKET\" 'NEW HEIGHTS GRILL'\n",
      " 'JHYRANI L- SUPER' 'UNIVERSITY AVENUE MARKET' 'ALPINE MARKETPLACE'\n",
      " 'SUNSHINE FOODS' \"LOWE'S MARKET\" \"BUC-EE'S\" 'VITACOST'\n",
      " 'LAKEWOOD SUPERVALU' 'BOTTOMS UP WINE  LIQUOR' 'HOLIDAY OIL'\n",
      " 'LA PLACITA SUPERMARKET' \"JOHNSON'S FOOD\" 'M & W MARKET' 'RISK'\n",
      " 'LIBERTY MARKET' 'MAYPORT NS COMMISSARY' \"BENNETT'S PIT BBQ-GATLINBURG\"\n",
      " 'AT RED HAWK RESORT  CASINO' 'TRANSACTION RECEIPT' 'MANET' 'BP'\n",
      " 'TIENDA EL PAISANO' 'CTOWN SUPERMARKETS' 'NORTHOATE 22 KKET'\n",
      " 'DANDY MINI MART' 'JONS INTERNATIONAL MARKETPLACE' 'SUPER' 'PETSMART'\n",
      " 'DOLLAR KING' 'AUSABLE INN' 'MET FOODMARKETS' 'CAMP PENDLETON COMMISSARY'\n",
      " 'SUPERVALU FOODS' \"CLARK'S MARKET\" 'HORNINGS OF' 'R P DY'\n",
      " 'FOOD DALESS PREE' 'THE ROOF' 'THE MARKET AT BIRCH BAY'\n",
      " 'LA FIESTA SUPERMARKETS' \"BROOKSHIRE'S FOODA PHARMACY\" 'FARMACIA CARIDAD'\n",
      " 'MEYER' 'CANTORO ITALIAN MARKET' 'DIAMONDSCAN' 'FOOD RAN' 'B'\n",
      " \"BERKOT'S SUPER FOODS\" 'EXPRESS' 'LONGS DRUGS' \"PHO KITCH'N\" 'SEPHORA'\n",
      " 'STKES FRACH FOODE' 'STRIPES' \"KESSLER'S FOOD & LIQUOR\"\n",
      " 'SUPERDESCUENTOS MORALES INC' 'THE OAKS GRILLE' 'QUALITY MARKET'\n",
      " 'FOID STORES' 'GLACT' 'Y DULCERIA LA BONITA PALETERIA'\n",
      " 'BEAUTY OUTLET OF HAMPTON' 'LOL' 'CURAAR SHOPPING CANTER' 'FISH HOUSE'\n",
      " 'S AVEIAL' 'KING SOOPERS FUEL' 'DVERS1OCK DISCOUNT CNTR'\n",
      " 'SEAFOOD CITY SUPERMARKET' \"JUNIOR'S SUPERMARKET\"\n",
      " 'FORT NOVOSEL COMMISSARY' 'DOG STREET' 'TELWAY' 'LA CONFIANZA'\n",
      " 'BREAK TIME' 'FOOD FAIR SUPERMARKET' 'THE TRUE LOW PRICE LEADER'\n",
      " 'THORNTONS' 'APP LE MARKET' 'ALOHA FROM BLIND VENDORS' 'NICHOLASYILLE'\n",
      " 'BAILEYS PRODUCE & NURSERY' 'ADAMS FAIRACRE FARMS' 'ALBERGUE OLIMPICO'\n",
      " 'CARNICERIA LOS DOS RIOS' 'EL CABRITO MEXICAN RESTAURANT' 'S DRN MY'\n",
      " 'MAPCO MART' 'TART TINS' 'MONONGAHELA' \"K'S BESTWAY GROCERY\"\n",
      " 'MARINE CORPS EXCHANGE' 'PHILLIPS 66' 'ALOME CINEMA GRILL'\n",
      " 'FANCY FRUIT & PRODUCE' 'KUM & GO' \"SEDANO'S\" 'ALAYO'\n",
      " \"R REDNER'S SINCE 1976\" 'PRESTON FOODS' 'TINKER COMMISsARY'\n",
      " 'ASIAN HARBOR' 'GASOLINE ALLEY' 'VALLEY FOOD SUPERMARKET' 'ELA VIR BE'\n",
      " 'PITT STOP' \"F OOD TORES RY'S\" 'BOOTLEGGERS LIQUOR OUTLET' 'PARALARRIS'\n",
      " 'EREWHON MARKET' 'WTHOGANS' \"STEWART'S MARKETPLACE\"\n",
      " \"FRANK'S FRESH MARKET\" 'FORT MCCOV COMMISSARY' 'FUEL CITY' 'URB. CUIDAD'\n",
      " 'SGROCERY & VARIETY-' 'RULER FOODS' 'COLUMBIA ORTHOPA' 'HY MMPLOYEECWNID'\n",
      " 'DILLONS 7OO STUBES' 'HU VEE EHPLOVER CUNED' 'GREEN HILLS FARM'\n",
      " 'PATEL BROTHERS' 'BI-MART' 'SPINX' \"ALLSUP'S\" 'MEXICO MARKET'\n",
      " 'NORTHOATE MARKETR' 'SAV-A-LOT CENTERS NUTRITION' 'MONONGAHELA HOSPITAL'\n",
      " \"QUINN'S SUPER MARKET\" 'FIESTA GRANDE' 'SAV-ON PHARMACY'\n",
      " 'FAIRPLAY FINER FOODS' 'GET-GO' 'BASKET ARKET' \"FRY'S FOOD AND DRUG FUEL\"\n",
      " 'CARNICERIA GONZALEZ' 'EDWARDS FOOD GIANT' 'OMC SMOKEHOUSE' \"HUGO'S\"\n",
      " 'CITY FRESH MARKET' 'SHCOTOS' 'CEE BEE FOOD STORE'\n",
      " 'WEEMERS DISCOUNT GROCERIES' 'HAWES MMARKETH' 'DISTRICT MARKET'\n",
      " 'BIG BOSS BIG BOSS' 'MINARE' 'FOOD WORLD SUPERMARKET' 'URBAN PIE'\n",
      " 'CUMBERLAND FARMS' 'BROTHERS FOOD MARKET' 'OVAL SUPERA' 'PEN MART,'\n",
      " 'WAIMA' \"R REDNER'S 1970\" 'LEWIS DRUG' 'WEE' \"RU MEASUR'A\"\n",
      " 'ASTAN FOOD MAK' 'BLISS BEAUTY SUPPLY' \"HATILLO KASH N' KARRY\" \"MACY'S\"\n",
      " 'GROCERY' 'GLENWOOD FOODS' 'IPHARMACY' 'STOTER R BROS MARKETS'\n",
      " 'HARPS MOMETOWN FRE4M' 'ALAYOS' 'KHOUT' 'MI RANCHO SUPERMARKET'\n",
      " 'MAEEYS HOPPY' \"HORNING'S MARKET OF BETHEL\" 'NBK BANGOR COMMISSARY'\n",
      " 'FODD WLESS' 'PLAZA LIQUORS' 'EL RIO GRANDE' 'BLUE SUNERESH' \"WENDY'S\"\n",
      " 'THE FOOD EMPORIUM' \"OLLIE'S BARGAIN OUTLET\" 'CENEX' 'MI PUEBLO'\n",
      " 'DORITOS SS BOGO' 'THERRESNEROCER' 'LIQUOR & CONVENIENCE STORE'\n",
      " 'TERRY DRUGS' 'TARJET' 'HOMETOWN FOODS' 'BEAUTY EXCHANGE' 'PHARMAMAX'\n",
      " 'SUNFLOWER' \"ARMANDO'S SUPERMARKET\" 'F RY' 'DECICCO FAMILY MARKETS'\n",
      " 'HANSCOM COMMISSARY' 'HOMETOWN 15' 'FRESH VALUE'\n",
      " 'JOLLA BELLA BEAUTY SUPPLY' 'EL RANCHO SUPERMERCADO' 'LOT-LESS CLOSEOUTS'\n",
      " \"ANGELI'S CENTRAL MARKET\" 'FOODWAY' 'COPPS' 'EL MOLCAJETE LOCO'\n",
      " 'MARKETON' 'BAINBOW GROCERY' 'HANDY PANTRY' 'WILDFIRE'\n",
      " 'BUTLER FARM MARKET' \"DAN'S SUPERMARKET\" 'HACKENSACK MARKET'\n",
      " 'ORD COMMUNITY COMMISSARY' 'SARASWATI 1 INC' \"BELL'S FOOD STORE\"\n",
      " 'EMART ISMEN' 'AUTOZONE' 'OLD NAVY' \"JANE'S PHARMACY\"\n",
      " 'HARPS MOMHTCWH PBKS' 'INCO FOODS' 'SURPLUS OUTLET' \"JOE V'S SMART SHOP\"\n",
      " 'ALQI' 'TL FES VEY' 'FRESH WORLD' 'FOOD STORES' 'TOM WIML' 'FOOD RITE'\n",
      " 'DUANE READE' \"ROOHE'S IGN MAXCICLACE\" 'SSARY COMMI INCY'\n",
      " 'WALNUT CREEK CHEESE' 'CONMONIENCE' 'SAR' 'ANDERSEN AFB' 'MAXWAY'\n",
      " 'KSHO2, INC' \"RAMEY'S MARKETPLACE\" 'SOVAELAFTA' 'PATA NEGRA'\n",
      " 'AZTECA SUPERMERCADO' '99 CENTS ONLY STORES'\n",
      " 'VILLAGE SOAP CO. KITCHEN KETTLE VILLAGE' 'GROCERY MART'\n",
      " 'RRIS TEETER HAT NEIOHBORHOOD MARKET' 'PIC PAC SUPERMARKET' 'COST LE5S'\n",
      " \"GREEN'S\" \"GENO'S SPORTS BAR AND GRILL\" 'LOAF N JUG' 'SFIC.'\n",
      " 'SBER S COUNTA STORE BULK FOOD' \"ELROD'S COST PLUS\" 'AT HOME'\n",
      " 'SHORTONE MARKET' 'MAVERIK' 'BEAUTY DEPOT' 'HEBOES WEST' 'CHY' \"HEINEN'S\"\n",
      " 'NORTH SHORE FARMS' 'DREAM MARKET' 'SOOPER' \"DICKEY'S BARBECUE PIT\"\n",
      " 'COST LESS FOOD COMPANY' 'BESTWAY SUPERMARKET' 'SUPER MERCADO MEXICO'\n",
      " 'SUPERMERCADOS MR. SPECIAL' \"BUTCHER'S GRILLE\" 'FARMERS' '7TH HEAVEN'\n",
      " 'BANLAFOR' 'MILLERS WHERE COSTS S YOU LESS' \"ANAYA'S MARKET\" 'RN EFOO'\n",
      " 'SPRIROFIALS' 'FATRVTEW PHARMACY' 'INHNITY CARE' 'GOODWILL'\n",
      " 'NYC FRESH MARKET' 'ANPOCNMNA' 'STOM LAMIARDS' 'GRANTS SUPERMARKET'\n",
      " 'CHEF CHEN ASIAN CUISINE' 'R-N MARKET' 'PANINIS' 'MISS MAMIES' \"WEIGEL'S\"\n",
      " 'EL-DCE' \"ETWILER'S FARM MARKET FRESH FOR LESS\"\n",
      " \"SHERM'S THUNDERBIRD MARKET\" 'JUST SAVE FOODS' \"HUGO'S FAMILY PHARMACY\"\n",
      " 'RATON TRUCK STOP' 'FORT STEWART COMMISSARY' 'ELK COUNTY FOODS'\n",
      " 'VIGROCEE' 'CAMP LEJEUNE MCB COMMISSARY' 'CONTINENTAL MIDTOWN'\n",
      " 'WAIANAE STORE' 'ASSOCIATED SUPERMARKET' '57 BAYARD STREET'\n",
      " 'GLENWOOD FOODS AT GREENCASTLE' 'SUPER MERCADO MONTERREY'\n",
      " 'BELEVILLE PHARMACY' 'NOGALES LLC MARKET' 'MELROSE FAMILY FASHIONS'\n",
      " \"WALT CHURCHILL'S MARKET\" 'EL SOL MEAT MARKET' 'FOOD MARKET LA CHIQUITA'\n",
      " 'OSCEOLA FOOD MART' 'BEMGAORS' 'FORT MYER COMMISSARY'\n",
      " 'DELISH NEW AMERICAN GRILL' 'LOCUST VALLEY MARKET' 'FOOD BASKET'\n",
      " 'BURKES OUTLET' \"BB'S GROCERY OUTLET\" \"FSCARFALLOTO' HOMETOWN MARKET\"\n",
      " 'DRIVE YHRU' 'CANNON AEB COMMISSARY' 'FINE WINE & SPIRITS STORES'\n",
      " \"DOUG'S SUPERMARKET\" 'OUTLET BEAUTY SUPPLY' 'FOOD DYNASTY' 'PIC-PAC'\n",
      " 'WOODS SUPERMARKET' 'WINGCRAFT' 'WEAVER MARKETS' 'FARMACIAS PLAZA'\n",
      " 'MIDWEST' 'THRIVE MARKET' 'CITGO' 'PETRO SERVE USA' 'STOOKEY MART'\n",
      " 'EL REY SUPER FOODS' 'RT 10 FARMERS MARKET' \"SENDIK'S FOOD MARKET\"\n",
      " 'WHISKEY RANCH' \"SAM'S FARMERS MARKET\" 'NU CASSEL PHARMACY' 'P PHARMACU'\n",
      " 'AMERIMART' 'QUIKSTOP' 'KINNEY DRUGS' \"INCOLLINGO'S FAMILY MARKET\"\n",
      " \"JIMMY'S STEAKOUT\" 'GREAT WALL SUPERMARKET' 'BNDGE STREET PHARMACY IC'\n",
      " \"KUHN'S MARKET\" 'BOTTLE KING' 'TARERMARKET' 'MEKONG SUPERMARKET'\n",
      " 'S RESTAURANTS' 'FOOD LESS THE TRUE LAW' 'TOWN & COUNTRY FOODS'\n",
      " \"COBORN'S\" 'ALAYSOO' 'GORDON FOOD SERVICE STORES' 'SAV MOR FOODS'\n",
      " 'TOWN & COUNTRY' 'P&L COUNTRY MARKET' 'GIAST' \"PARKER'S KITCHEN\"\n",
      " 'CULEBRA MEAT MARKET' \"LANDI'S SUPERMARKET\" 'SUPERMARKETS'\n",
      " 'MI TIERRA SUPERMERCADO' 'THOMAS MARKET' 'EL MARIACHI RESTAURANT' 'SPAGO'\n",
      " 'ASIAN MARKET' 'TRAVELCENTERS OF AMERICA' 'MARSEILLES FAMILY RESTAURANT'\n",
      " \"HERBIE'S BURGERS\" \"SEITTER'S MARKET\" \"MCKEEVER'S MARKET & EATERY\"\n",
      " 'NEW WEST ZONE SUPERMARKET' \"MANAFORD'S\" 'SUPER MERCADOS EL GUERO'\n",
      " 'RELECIOS A/MEOR PRECIOR' 'THE MARINERS' 'BLACK BEAR BAR & GRILL'\n",
      " 'MARKETPLACE' 'CHAR&LEMON' 'FUNCTIONOFBEAUTY.COM' 'EL CHURRASCASO, GRILL'\n",
      " 'ONE STOP' 'HURLBURT FIELD COMMISSARY' 'POPEYES' 'STOTER BROS'\n",
      " \"TOM'S FOOD MARKETS\" 'RULLI BROS' 'CAPRI' 'TARMACIA SAN ANTONIO' 'SOMA'\n",
      " 'AG PIZZA' 'FORT CARSON COMMISSARY' \"ALACURT'S\" 'REDMEYER'\n",
      " 'PENNY PINCHERS' 'YESWAY' 'PHARMAMAY CABO RJO' 'MERCATE'\n",
      " \"BUSCH'S FRESH FOOD MARKET\" 'MCX' \"JACK'S MARKET\" 'ASHOPPERS'\n",
      " 'TO GO STORE' 'FOOD COUNTRY USA' 'PLATEAU TRAVEL CENTER']\n",
      "\n",
      "Unique Values in STORE_NAME Column After Validation:\n",
      "['Walmart' 'Aldi' 'Food Lion' 'Randalls' 'Target' 'Costco'\n",
      " 'Dollar Tree Stores Inc' 'Family Dollar' 'Kroger' 'Foods Co'\n",
      " 'Reaes Store' 'Iga' 'Dollar General Store' 'Publix' \"Macey'S\" 'Walgreens'\n",
      " 'Cvs' 'Winco Foods' 'The Home Depot' 'Fred Meyer' 'Market Basket'\n",
      " '7-Eleven' 'Hobby Lobby' 'Giant Eagle' 'Hy-Vee' \"Sam'S Club\"\n",
      " 'Whispering Pines Fruit Farms' 'Jewel Osco' 'Shell' 'Neles Granacot'\n",
      " \"Trader Joe'S\" 'Five Below' 'Grocery Outlet Bargain Market' 'Smart Shop'\n",
      " 'Tinken Afb Commie' 'Albertsons' 'Lidl' 'Pharmacy' 'Weis' 'Fastrac'\n",
      " 'Rite Aid' 'Meijer' 'Commissary' 'Foodland' 'Pal Campo Restaurant'\n",
      " \"Bj'S Wholesale Club\" 'Carrs' 'Shop Rite' 'Plavers Cafe Lida'\n",
      " 'Winn-Dixie' 'Safeway' 'Mi Tienda' 'Circle K' 'Nuts Factory 74Th'\n",
      " 'Amazon' \"Marc'S\" 'Wegmans' 'Schnucks' 'Food Depot' 'Burger King' 'H-E-B'\n",
      " 'Pioneer Supermarkets' 'King Soopers' 'Festival Foods' 'Tj Maxx'\n",
      " \"Smith'S\" \"Woodman'S Market\" 'Bravo Supermarkets' 'Gomart' 'Hannaford'\n",
      " 'Qfc' 'Kwik Trip' 'Market' 'Acme' \"Love'S\" 'Food Outlet' 'Harris Teeter'\n",
      " 'Star Market' 'The Giant Co' 'Giant Food' 'Express Roses' 'Price Chopper'\n",
      " 'Pavilions' 'Food Bazaar Supermarket' 'John Deere Hq' 'Food City'\n",
      " 'Ralphs' 'Petco' 'Ponte Fresco' \"Dillon'S Food Store\" 'Pueblo'\n",
      " 'Pick N Save' 'Presidente Supermarkets' 'Main Street Market' 'Food Fair'\n",
      " 'La Gloria Supermercado' 'Fareway' 'Stop & Shop' 'Food 4 Less' 'Big Lots'\n",
      " 'Enorthgate Market' 'Your Dekalb Farmers Market' \"Martin'S Supermarket\"\n",
      " 'Prime Time Nutrition' 'The Fresh Market' \"Witbeck'S Family Foods\"\n",
      " 'Key Food Fresh' 'Riggins Water White Market'\n",
      " 'Hibachi Japanese Stk House' 'Wawa' 'Tops Markets' 'Sunoco'\n",
      " 'Rouses Market' 'Rabers' \"Redner'S Markets\" \"Dave'S Marketplace\"\n",
      " \"Stew Leonard'S\" \"Ralph'S Caquas\" 'Marshalls' 'Supermercado Torres'\n",
      " 'Metro Market' 'Food Maxx' \"Braun'S Food Center\" 'Farmers Super Market'\n",
      " 'Supermax' \"Buehler'S Fresh Foods\" 'Piggly Wiggly' 'Super Saver'\n",
      " 'Sun Mart Foods' 'Exchange' 'Cub Foods' 'Gas N Go'\n",
      " \"John'S Grocery & Hardware\" \"Riesbeck'S Food Market\" \"Shaw'S\" 'Giant'\n",
      " 'Save Mart Supermarkets' 'Flying J' 'Mc' 'Giant Food Store Fuel'\n",
      " 'Price Cutter' 'Compare Foods' 'Stater Bros' 'Anazeh Sands Billiards'\n",
      " 'Ulta Beauty' 'Super 1 Foods' 'Tom Thumb' 'Supremo Food Market'\n",
      " 'La Bonita Supermarkets' \"It'Sugar\" 'Holiday Market' \"King'S Supermarket\"\n",
      " 'Sprouts Farmers Market' 'Foodtown' 'Lucky Supermarket'\n",
      " 'Whole Foods Market' 'Zoob Zib Thai Authentic Noodle Bar' 'Osco'\n",
      " 'El Super' 'Supermercados Selectos' 'Lotte Plaza Market'\n",
      " 'Vegas Food Center' 'Fairplay' 'Cosico Tholesale'\n",
      " 'International Foodmart' 'Food12' 'Patrick Afb Commissary' 'Ni Pueblo'\n",
      " 'Speedway' 'Northgate Market' 'Ingles' 'Strack & Van Til' 'Bel Air'\n",
      " 'Doordash Deliv' 'County Market' \"Fry'S Food Store\" 'Super Fresh'\n",
      " 'Payless' 'Save A Lot' 'Vons' 'Palisades' 'Dollar Saver'\n",
      " 'Mai Ket We Do Beef The Best Alber Tsons Market The Best We Do Beef'\n",
      " 'Jay C Food Stores' 'Lazy Acres' 'Sheetz' \"Brookshire'S\" 'Tierma'\n",
      " \"Bashas'\" 'Kwik Shop' 'Elgin Fresh Market' 'Restaurant Depot'\n",
      " 'Fresco Y Más' 'Smart & Final' 'Therresderocer' 'Murphy Usa'\n",
      " \"Boyer'S  Food Market\" 'Valero' 'City Market' 'Shop N Save'\n",
      " 'Canary Roost' 'Me Salve' 'Kismet Bialys' \"Mariano'S\" 'Exxon'\n",
      " 'Amazonfresh' 'Commi5Sare' 'Stauffers Of Kissel Hill'\n",
      " 'Carniceria Potosina' 'Nt Gia' 'Ing Jefe Tacosar' 'Kroger Fuel'\n",
      " 'Bargain Hunt' 'Econofoods' 'Food Giant' 'Price Utter' 'Fiesta Mart'\n",
      " 'Popshelf' 'New Morning Market' 'Wholesale' 'Lode' '4 Way Meat Market'\n",
      " 'Quiktrip' 'Hancocks Neighborhood Market' \"Teal'S Market\"\n",
      " 'The Atlantic Hotel' 'Key Food Marketplace' 'Dierbergs' 'Pricerite'\n",
      " 'Modern Market' 'Supercenter' \"Ridley'S Family Markets\" 'Belmont Market'\n",
      " 'Toou Ordg' 'Costco Fuel' \"Belacino'S\" 'Grecian Steakhouse'\n",
      " 'Rrieno Sour A Rals Lgrocerh' 'Wbc Hob' 'Ghuirks'\n",
      " \"Lowe'S Home Improvement\" '1Ainting Cusval Bistro'\n",
      " 'Sun Valley Fine Foods' 'Amvets Post 11' 'Valley Pharmacy'\n",
      " 'Nob Hill Foods' 'Dollad Enerol' 'Kta Super Stores' 'Bojangles'\n",
      " \"Tony'S Fresh Market\" 'Seheral' 'Beauty Supply' 'La’Bonne’S Markets'\n",
      " 'Tort Sam Tnton Commissary' 'Five Belov' 'Alct' 'Macs Fresh Market'\n",
      " 'Sentara Leigh Dutnatient' 'Bienvenidos Mexican Restaurant'\n",
      " 'Riverview Family Center' 'Ermercados Supe Mr. A Peg' 'Fast Track'\n",
      " 'Super Supermarket' 'Fresh Thyme Market' \"Sleepers' Market\" 'Center'\n",
      " 'Supermercados Econo' 'Mace Ys Arket' \"Owen'S\" 'Saloncentric'\n",
      " 'Valuefresh' 'Co Com' 'Vallarta Supermarkets' 'Cf Marks'\n",
      " \"Cattleman'S Roadhouse\" 'Eway Sar' 'Avi Foodsystems, Inc.'\n",
      " 'The Fresh Grocer' \"Reasor'S\" \"Chappell'S Hometown Foods\" 'Ompe Gfoods'\n",
      " \"Andronico'S Community Markets\" 'Racetrac' 'Camil/Dotlar' 'Roses'\n",
      " 'Menards' 'Flowers Baking Co' 'Northwoods Wholesale Outlet' 'Lewer Csco'\n",
      " 'Defense Commissary Agency' \"Webster'S Marketplace\" 'Riggins'\n",
      " 'Mosquito Bookslkobuk To Go' 'E W James & Sons Supermarkets'\n",
      " 'Superior Grocers' \"Casey'S General Store\" 'Cardenas'\n",
      " 'Unshine Hse Hath Foods' \"Kohl'S\" \"Broulim'S\" 'Fresh 4 Less'\n",
      " 'Mills Fleet Farm' 'Roche Bros. Supermarket' 'Armitage Produce'\n",
      " 'Office Supplies Dorado School &' \"Needler'S Fresh Market\"\n",
      " 'General Discount' \"Raley'S\" 'Our Pharmacy' 'Hudson'\n",
      " \"Casel'S Supermarket\" 'Dillons Cooc Stores' 'Estrella Super Market'\n",
      " 'Hometown Grocery' 'Mint Co Fo0 S' 'Asia Market' \"Dick'S Sporting Goods\"\n",
      " \"J'S Salvage\" 'Staples' 'Crest Foods' \"Reoner'S\" 'Gw Supermarket'\n",
      " 'Cash Wise' 'Ru' 'Rochita Plaza Mark' 'Lveryone'\n",
      " 'Fort Jackson Commissary' 'Eamtly Restaurant' 'Priceless Foods' 'Al'\n",
      " 'Cash Saver' 'Eataly' \"Mike'S Discount Foods\" 'Amigo'\n",
      " 'Discount Drug Mart' 'Super Discount Tobacco' 'Merchant Cou'\n",
      " \"Detwiler'S Farm Market\" 'Fiesta Foods' 'Bethpage Pharmacy'\n",
      " 'Sodle Pharmacy' 'H Mart' 'Nam Dae Mun Farmers Market' \"Froogel'S\"\n",
      " 'Thrifty Produce & Meat' 'Rhodes Family Price Chopper' 'Lowes Foods'\n",
      " 'Market Street' \"Moser'S Discount Foods\" 'Sparkle Market'\n",
      " \"Jungle Jim'S International Market\" 'Harps Food Stores' 'Top Tomato'\n",
      " \"Fresh N' Low\" 'Schedule & Save' 'Schofield Barracks Commissary'\n",
      " 'Total Wine & More' 'Chick-Fil-A' 'Great Giant Supermarket'\n",
      " 'Gerbes Super Markets' \"Crosby'S\" 'Viet Hoa International Foods'\n",
      " 'Toro De Oro Market' 'Mart' 'Totopos Mexican Grill' 'Cinemark Theatres'\n",
      " 'Los Aztecas' 'Market 32' 'Dsaloncentrid' 'Shop Fair Supermarkets'\n",
      " 'Neighborhood Discount Supermarket' 'Big Y World Class Market'\n",
      " 'C Tco Lesale Who' \"Pete'S Market\" 'Poulevaru' 'C&C Candies' \"Dodge'S\"\n",
      " 'Md Oriental Market' 'Drive-In Restaurant Justrite' \"Trig'S\"\n",
      " 'Jacksonville Nas Commissary' \"Ru'S\" 'The Oak Cupboard' 'Tek Markets'\n",
      " \"Schiel'S Family Market\" 'Shoppers' \"Baker'S\"\n",
      " \"Saito'S Japanese Steakhouse\" 'Country Mart' 'Trade Fair Supermarket'\n",
      " 'Pilot' 'Martindales Natural' 'Marketplace Foods' 'Lunds & Byerlys'\n",
      " \"Wome'S\" \"Caraluzzi'S Market\" 'Big Deal Outlet' 'Conoco' 'Mart Walr'\n",
      " 'Royal Farms' 'Lihe Horseshob' 'Dillons Fuel' \"Woodman'S Fuel\"\n",
      " 'Sunset Foods' 'Patriot Store' 'Stole25' 'Super Brayd'\n",
      " \"Schneider'S Market\" 'Brookshire Brothers' 'El Indio - Manchester'\n",
      " 'H. Yaniris' \"Son'S Parrish\" 'Fresh Foods' 'Seledlos Be Todo/Agusto'\n",
      " \"Gerrity'S Supermarkets\" 'Nellis Afb Commissary' \"Hornbacher'S\"\n",
      " 'Country Market Inc.' 'Yoods Cy' \"Paton'S Market Place\"\n",
      " 'Apples Grocery Store' 'Community Markets' \"Uncle Giuseppe'S Marketplace\"\n",
      " \"Concessi'S Furo Market\" \"Michael'S\" 'Ocracoke Variety'\n",
      " 'Booneville Shopwise' 'Karns Quality Foods' 'Penn Sparkle'\n",
      " \"De' Fresh Market\" 'Shop A Lott' 'Ponts Fresco' 'Royals Liquor'\n",
      " 'The Turn Club' 'Family Fare Supermarkets' 'Tyndall Afb Commissary'\n",
      " 'St Lukes Outpatient' 'Rmercados Super Mro Peoa' 'Chevron'\n",
      " '10Box Cost-Plus' 'A Cme Durp Superak' 'Dejan' 'Food King'\n",
      " \"Ric'S Food Center\" 'New Asia Supermarket' 'Pier17'\n",
      " 'Fine Fare Supermarket' 'King Kullen' \"Buddy'S Crabhouse Oyster Bar\"\n",
      " \"Ozzie'S Fresh Market By Food Universe\" 'Market Fresh' 'The Back Forty'\n",
      " 'Firelake Express Grocery' 'Ace Hardware' 'Freshco'\n",
      " 'Hospital Drive Pharmacy' 'Cherry Valley Marketplace' 'Jr Food'\n",
      " 'Western Beef' \"Raley'S Service Center At\" 'Taco Rio' 'Jcpenney'\n",
      " 'Foodarama' 'Ar Disney World.' 'Supermercado Napo Velez'\n",
      " 'Navarro Discount Pharmacies' 'Siesca' 'Shoppers Value Foods'\n",
      " 'Baptist Health' 'Harveys Supermarket' 'Kinneudrugs' 'White & Case Cafe'\n",
      " 'La Panza Feliz' 'Ses Moo Market' 'La Frontera' \"Il''S Whiolesale Club\"\n",
      " 'Marathon' 'Kwik Fill' 'Kwik Star' 'Ssary Commi' \"Dick'S\"\n",
      " 'Changsfood2020' 'Cre St Foods' 'Wooden Nickel'\n",
      " 'Buford Highway Farmers Market' \"K Ent 'S Marke\" 'Hartig' 'Nordstrom'\n",
      " 'Food Zone' \"Braum'S Ice Cream And Dairy Stores\" 'Www.Shopmar Marve'\n",
      " 'Spirits' 'Fort Buchanan Commissary' 'Homeland' 'Farm Fresh' 'Alta'\n",
      " 'Freameyer' 'Ses 00 W Market' 'Leppinks Food Centers'\n",
      " \"Schulte'S Fresh Foods\" 'La Michoacana'\n",
      " 'The S Hhant Or 2010 Mmily Rn /Taves' 'Holiday Stationstore' 'Short Stop'\n",
      " 'San Diego Nb Commissary' '/Mart' 'Big Saver Foods'\n",
      " \"Gordon'S Select Market\" 'Aries Supermarket' 'Pepperidge Farm'\n",
      " 'Scott Afb Commissary' 'Festit Al' \"Cluls Sam'S\" 'Venture Foods'\n",
      " \"Laura'S Pharmacy\" 'Mount Ain Super Fresh Market' 'Farmacia Corcovapa'\n",
      " 'The Half Wall Beer House' \"Helen'S Of Ellsworth\" 'Express Lane'\n",
      " 'Town & Country Supermarket' 'Apermercadoss Mrs Porque Tu Arus Escocinin'\n",
      " 'Yallah Taco' 'Summa Health' 'Sellers Bros' \"Butcher'S Brewhuis\" 'Store'\n",
      " 'United Supermarkets' 'Harris Teeter Fuel' \"Champagne'S Marche\"\n",
      " 'Western Union' 'The Fridge' 'H.F Dollar & Up' 'Corral'\n",
      " 'Cermak Fresh Market' 'Azucar Cuban Cuisine' 'Se Ectos'\n",
      " 'Troyer Country Market' \"Woodruff'S Market\" 'New Heights Grill'\n",
      " 'Jhyrani L- Super' 'University Avenue Market' 'Alpine Marketplace'\n",
      " 'Sunshine Foods' \"Lowe'S Market\" \"Buc-Ee'S\" 'Vitacost'\n",
      " 'Lakewood Supervalu' 'Bottoms Up Wine  Liquor' 'Holiday Oil'\n",
      " 'La Placita Supermarket' \"Johnson'S Food\" 'M & W Market' 'Risk'\n",
      " 'Liberty Market' 'Mayport Ns Commissary' \"Bennett'S Pit Bbq-Gatlinburg\"\n",
      " 'At Red Hawk Resort  Casino' 'Transaction Receipt' 'Manet' 'Bp'\n",
      " 'Tienda El Paisano' 'Ctown Supermarkets' 'Northoate 22 Kket'\n",
      " 'Dandy Mini Mart' 'Jons International Marketplace' 'Super' 'Petsmart'\n",
      " 'Dollar King' 'Ausable Inn' 'Met Foodmarkets' 'Camp Pendleton Commissary'\n",
      " 'Supervalu Foods' \"Clark'S Market\" 'Hornings Of' 'R P Dy'\n",
      " 'Food Daless Pree' 'The Roof' 'The Market At Birch Bay'\n",
      " 'La Fiesta Supermarkets' \"Brookshire'S Fooda Pharmacy\" 'Farmacia Caridad'\n",
      " 'Meyer' 'Cantoro Italian Market' 'Diamondscan' 'Food Ran' 'B'\n",
      " \"Berkot'S Super Foods\" 'Express' 'Longs Drugs' \"Pho Kitch'N\" 'Sephora'\n",
      " 'Stkes Frach Foode' 'Stripes' \"Kessler'S Food & Liquor\"\n",
      " 'Superdescuentos Morales Inc' 'The Oaks Grille' 'Quality Market'\n",
      " 'Foid Stores' 'Glact' 'Y Dulceria La Bonita Paleteria'\n",
      " 'Beauty Outlet Of Hampton' 'Lol' 'Curaar Shopping Canter' 'Fish House'\n",
      " 'S Aveial' 'King Soopers Fuel' 'Dvers1Ock Discount Cntr'\n",
      " 'Seafood City Supermarket' \"Junior'S Supermarket\"\n",
      " 'Fort Novosel Commissary' 'Dog Street' 'Telway' 'La Confianza'\n",
      " 'Break Time' 'Food Fair Supermarket' 'The True Low Price Leader'\n",
      " 'Thorntons' 'App Le Market' 'Aloha From Blind Vendors' 'Nicholasyille'\n",
      " 'Baileys Produce & Nursery' 'Adams Fairacre Farms' 'Albergue Olimpico'\n",
      " 'Carniceria Los Dos Rios' 'El Cabrito Mexican Restaurant' 'S Drn My'\n",
      " 'Mapco Mart' 'Tart Tins' 'Monongahela' \"K'S Bestway Grocery\"\n",
      " 'Marine Corps Exchange' 'Phillips 66' 'Alome Cinema Grill'\n",
      " 'Fancy Fruit & Produce' 'Kum & Go' \"Sedano'S\" 'Alayo'\n",
      " \"R Redner'S Since 1976\" 'Preston Foods' 'Tinker Commissary'\n",
      " 'Asian Harbor' 'Gasoline Alley' 'Valley Food Supermarket' 'Ela Vir Be'\n",
      " 'Pitt Stop' \"F Ood Tores Ry'S\" 'Bootleggers Liquor Outlet' 'Paralarris'\n",
      " 'Erewhon Market' 'Wthogans' \"Stewart'S Marketplace\"\n",
      " \"Frank'S Fresh Market\" 'Fort Mccov Commissary' 'Fuel City' 'Urb. Cuidad'\n",
      " 'Sgrocery & Variety-' 'Ruler Foods' 'Columbia Orthopa' 'Hy Mmployeecwnid'\n",
      " 'Dillons 7Oo Stubes' 'Hu Vee Ehplover Cuned' 'Green Hills Farm'\n",
      " 'Patel Brothers' 'Bi-Mart' 'Spinx' \"Allsup'S\" 'Mexico Market'\n",
      " 'Northoate Marketr' 'Sav-A-Lot Centers Nutrition' 'Monongahela Hospital'\n",
      " \"Quinn'S Super Market\" 'Fiesta Grande' 'Sav-On Pharmacy'\n",
      " 'Fairplay Finer Foods' 'Get-Go' 'Basket Arket' \"Fry'S Food And Drug Fuel\"\n",
      " 'Carniceria Gonzalez' 'Edwards Food Giant' 'Omc Smokehouse' \"Hugo'S\"\n",
      " 'City Fresh Market' 'Shcotos' 'Cee Bee Food Store'\n",
      " 'Weemers Discount Groceries' 'Hawes Mmarketh' 'District Market'\n",
      " 'Big Boss Big Boss' 'Minare' 'Food World Supermarket' 'Urban Pie'\n",
      " 'Cumberland Farms' 'Brothers Food Market' 'Oval Supera' 'Pen Mart,'\n",
      " 'Waima' \"R Redner'S 1970\" 'Lewis Drug' 'Wee' \"Ru Measur'A\"\n",
      " 'Astan Food Mak' 'Bliss Beauty Supply' \"Hatillo Kash N' Karry\" \"Macy'S\"\n",
      " 'Grocery' 'Glenwood Foods' 'Ipharmacy' 'Stoter R Bros Markets'\n",
      " 'Harps Mometown Fre4M' 'Alayos' 'Khout' 'Mi Rancho Supermarket'\n",
      " 'Maeeys Hoppy' \"Horning'S Market Of Bethel\" 'Nbk Bangor Commissary'\n",
      " 'Fodd Wless' 'Plaza Liquors' 'El Rio Grande' 'Blue Suneresh' \"Wendy'S\"\n",
      " 'The Food Emporium' \"Ollie'S Bargain Outlet\" 'Cenex' 'Mi Pueblo'\n",
      " 'Doritos Ss Bogo' 'Therresnerocer' 'Liquor & Convenience Store'\n",
      " 'Terry Drugs' 'Tarjet' 'Hometown Foods' 'Beauty Exchange' 'Pharmamax'\n",
      " 'Sunflower' \"Armando'S Supermarket\" 'F Ry' 'Decicco Family Markets'\n",
      " 'Hanscom Commissary' 'Hometown 15' 'Fresh Value'\n",
      " 'Jolla Bella Beauty Supply' 'El Rancho Supermercado' 'Lot-Less Closeouts'\n",
      " \"Angeli'S Central Market\" 'Foodway' 'Copps' 'El Molcajete Loco'\n",
      " 'Marketon' 'Bainbow Grocery' 'Handy Pantry' 'Wildfire'\n",
      " 'Butler Farm Market' \"Dan'S Supermarket\" 'Hackensack Market'\n",
      " 'Ord Community Commissary' 'Saraswati 1 Inc' \"Bell'S Food Store\"\n",
      " 'Emart Ismen' 'Autozone' 'Old Navy' \"Jane'S Pharmacy\"\n",
      " 'Harps Momhtcwh Pbks' 'Inco Foods' 'Surplus Outlet' \"Joe V'S Smart Shop\"\n",
      " 'Alqi' 'Tl Fes Vey' 'Fresh World' 'Food Stores' 'Tom Wiml' 'Food Rite'\n",
      " 'Duane Reade' \"Roohe'S Ign Maxciclace\" 'Ssary Commi Incy'\n",
      " 'Walnut Creek Cheese' 'Conmonience' 'Sar' 'Andersen Afb' 'Maxway'\n",
      " 'Ksho2, Inc' \"Ramey'S Marketplace\" 'Sovaelafta' 'Pata Negra'\n",
      " 'Azteca Supermercado' '99 Cents Only Stores'\n",
      " 'Village Soap Co. Kitchen Kettle Village' 'Grocery Mart'\n",
      " 'Rris Teeter Hat Neiohborhood Market' 'Pic Pac Supermarket' 'Cost Le5S'\n",
      " \"Green'S\" \"Geno'S Sports Bar And Grill\" 'Loaf N Jug' 'Sfic.'\n",
      " 'Sber S Counta Store Bulk Food' \"Elrod'S Cost Plus\" 'At Home'\n",
      " 'Shortone Market' 'Maverik' 'Beauty Depot' 'Heboes West' 'Chy' \"Heinen'S\"\n",
      " 'North Shore Farms' 'Dream Market' 'Sooper' \"Dickey'S Barbecue Pit\"\n",
      " 'Cost Less Food Company' 'Bestway Supermarket' 'Super Mercado Mexico'\n",
      " 'Supermercados Mr. Special' \"Butcher'S Grille\" 'Farmers' '7Th Heaven'\n",
      " 'Banlafor' 'Millers Where Costs S You Less' \"Anaya'S Market\" 'Rn Efoo'\n",
      " 'Sprirofials' 'Fatrvtew Pharmacy' 'Inhnity Care' 'Goodwill'\n",
      " 'Nyc Fresh Market' 'Anpocnmna' 'Stom Lamiards' 'Grants Supermarket'\n",
      " 'Chef Chen Asian Cuisine' 'R-N Market' 'Paninis' 'Miss Mamies' \"Weigel'S\"\n",
      " 'El-Dce' \"Etwiler'S Farm Market Fresh For Less\"\n",
      " \"Sherm'S Thunderbird Market\" 'Just Save Foods' \"Hugo'S Family Pharmacy\"\n",
      " 'Raton Truck Stop' 'Fort Stewart Commissary' 'Elk County Foods'\n",
      " 'Vigrocee' 'Camp Lejeune Mcb Commissary' 'Continental Midtown'\n",
      " 'Waianae Store' 'Associated Supermarket' '57 Bayard Street'\n",
      " 'Glenwood Foods At Greencastle' 'Super Mercado Monterrey'\n",
      " 'Beleville Pharmacy' 'Nogales Llc Market' 'Melrose Family Fashions'\n",
      " \"Walt Churchill'S Market\" 'El Sol Meat Market' 'Food Market La Chiquita'\n",
      " 'Osceola Food Mart' 'Bemgaors' 'Fort Myer Commissary'\n",
      " 'Delish New American Grill' 'Locust Valley Market' 'Food Basket'\n",
      " 'Burkes Outlet' \"Bb'S Grocery Outlet\" \"Fscarfalloto' Hometown Market\"\n",
      " 'Drive Yhru' 'Cannon Aeb Commissary' 'Fine Wine & Spirits Stores'\n",
      " \"Doug'S Supermarket\" 'Outlet Beauty Supply' 'Food Dynasty' 'Pic-Pac'\n",
      " 'Woods Supermarket' 'Wingcraft' 'Weaver Markets' 'Farmacias Plaza'\n",
      " 'Midwest' 'Thrive Market' 'Citgo' 'Petro Serve Usa' 'Stookey Mart'\n",
      " 'El Rey Super Foods' 'Rt 10 Farmers Market' \"Sendik'S Food Market\"\n",
      " 'Whiskey Ranch' \"Sam'S Farmers Market\" 'Nu Cassel Pharmacy' 'P Pharmacu'\n",
      " 'Amerimart' 'Quikstop' 'Kinney Drugs' \"Incollingo'S Family Market\"\n",
      " \"Jimmy'S Steakout\" 'Great Wall Supermarket' 'Bndge Street Pharmacy Ic'\n",
      " \"Kuhn'S Market\" 'Bottle King' 'Tarermarket' 'Mekong Supermarket'\n",
      " 'S Restaurants' 'Food Less The True Law' 'Town & Country Foods'\n",
      " \"Coborn'S\" 'Alaysoo' 'Gordon Food Service Stores' 'Sav Mor Foods'\n",
      " 'Town & Country' 'P&L Country Market' 'Giast' \"Parker'S Kitchen\"\n",
      " 'Culebra Meat Market' \"Landi'S Supermarket\" 'Supermarkets'\n",
      " 'Mi Tierra Supermercado' 'Thomas Market' 'El Mariachi Restaurant' 'Spago'\n",
      " 'Asian Market' 'Travelcenters Of America' 'Marseilles Family Restaurant'\n",
      " \"Herbie'S Burgers\" \"Seitter'S Market\" \"Mckeever'S Market & Eatery\"\n",
      " 'New West Zone Supermarket' \"Manaford'S\" 'Super Mercados El Guero'\n",
      " 'Relecios A/Meor Precior' 'The Mariners' 'Black Bear Bar & Grill'\n",
      " 'Marketplace' 'Char&Lemon' 'Functionofbeauty.Com' 'El Churrascaso, Grill'\n",
      " 'One Stop' 'Hurlburt Field Commissary' 'Popeyes' 'Stoter Bros'\n",
      " \"Tom'S Food Markets\" 'Rulli Bros' 'Capri' 'Tarmacia San Antonio' 'Soma'\n",
      " 'Ag Pizza' 'Fort Carson Commissary' \"Alacurt'S\" 'Redmeyer'\n",
      " 'Penny Pinchers' 'Yesway' 'Pharmamay Cabo Rjo' 'Mercate'\n",
      " \"Busch'S Fresh Food Market\" 'Mcx' \"Jack'S Market\" 'Ashoppers'\n",
      " 'To Go Store' 'Food Country Usa' 'Plateau Travel Center']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Validate the STORE_NAME Column\n",
    "\n",
    "# Inspect unique values in the STORE_NAME column\n",
    "print(\"\\nUnique Values in STORE_NAME Column Before Validation:\")\n",
    "print(transactions['STORE_NAME'].unique())\n",
    "\n",
    "# Assumption:\n",
    "# - Case sensitivity and leading/trailing spaces might exist in the STORE_NAME column.\n",
    "# - We'll standardize the column to have a clean and uniform format.\n",
    "\n",
    "# Step 2: Remove any leading/trailing whitespace\n",
    "transactions['STORE_NAME'] = transactions['STORE_NAME'].str.strip()\n",
    "\n",
    "# Step 3: Convert the store names to Title Case for a clean, professional format\n",
    "transactions['STORE_NAME'] = transactions['STORE_NAME'].str.title()\n",
    "\n",
    "# Step 4: Handle missing values by replacing them with 'Unknown'\n",
    "transactions['STORE_NAME'] = transactions['STORE_NAME'].fillna('Unknown')\n",
    "\n",
    "# Validate changes by inspecting unique values again\n",
    "print(\"\\nUnique Values in STORE_NAME Column After Validation:\")\n",
    "print(transactions['STORE_NAME'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation and Standardization of RECEIPT_ID and USER_ID Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Duplicate RECEIPT_IDs: 25389\n",
      "Number of Missing USER_IDs: 0\n",
      "Number of Duplicate USER_IDs: 32135\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Validate RECEIPT_ID for Duplicates\n",
    "# Check for duplicate values in the RECEIPT_ID column to identify potential inconsistencies.\n",
    "duplicate_receipt_ids = transactions['RECEIPT_ID'].duplicated().sum()\n",
    "\n",
    "# Step 2: Validate USER_ID for Missing and Duplicate Entries\n",
    "# Check for missing values in USER_ID to ensure all transactions are linked to a user.\n",
    "missing_user_ids = transactions['USER_ID'].isnull().sum()\n",
    "\n",
    "# Check for duplicate USER_IDs to identify potential user-level inconsistencies.\n",
    "duplicate_user_ids = transactions['USER_ID'].duplicated().sum()\n",
    "\n",
    "# Display results for duplicate and missing values\n",
    "print(f\"Number of Duplicate RECEIPT_IDs: {duplicate_receipt_ids}\")\n",
    "print(f\"Number of Missing USER_IDs: {missing_user_ids}\")\n",
    "print(f\"Number of Duplicate USER_IDs: {duplicate_user_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To determine if the duplicate RECEIPT_IDs are genuinely duplicates or if they represent valid separate transactions,\n",
    "# we can group by RECEIPT_ID and inspect unique combinations of BARCODE and FINAL_QUANTITY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of Duplicate RECEIPT_IDs with Details:                               RECEIPT_ID  BARCODE  FINAL_QUANTITY\n",
      "7   00096c49-8b04-42f9-88ce-941c5e06c4a7        1               2\n",
      "13  001f2f3f-1746-4217-a98f-73c63c63bae2        1               2\n",
      "23  00496cd0-c7ad-408e-8f8f-9e02c58686c1        1               2\n",
      "31  005aca9a-4764-4bbe-a8b1-019c44882f15        1               2\n",
      "35  0063f1a2-bc74-47b9-9419-78194967b209        1               2\n",
      "Number of Duplicate RECEIPT_IDs Identified: 2322\n"
     ]
    }
   ],
   "source": [
    "# Step: Identify Duplicate RECEIPT_IDs with Unique BARCODE and FINAL_QUANTITY Combinations\n",
    "\n",
    "# Assumptions:\n",
    "# - Each RECEIPT_ID should ideally have unique combinations of BARCODE and FINAL_QUANTITY.\n",
    "# - Duplicate combinations may indicate multiple items in a receipt or data inconsistencies.\n",
    "\n",
    "# Findings:\n",
    "# - RECEIPT_IDs with more than one unique BARCODE or FINAL_QUANTITY are flagged for review.\n",
    "\n",
    "# Actions:\n",
    "# 1. Group data by RECEIPT_ID and count unique BARCODEs and FINAL_QUANTITY values.\n",
    "# 2. Identify RECEIPT_IDs with duplicate BARCODE or FINAL_QUANTITY entries.\n",
    "# 3. Retain these multi-item RECEIPT_IDs as valid for further analysis.\n",
    "\n",
    "# Group by RECEIPT_ID to check unique combinations of BARCODE and FINAL_QUANTITY\n",
    "receipt_id_grouped = transactions.groupby('RECEIPT_ID').agg({\n",
    "    'BARCODE': pd.Series.nunique,   # Count unique BARCODEs per RECEIPT_ID\n",
    "    'FINAL_QUANTITY': pd.Series.nunique  # Count unique FINAL_QUANTITY values per RECEIPT_ID\n",
    "}).reset_index()\n",
    "\n",
    "# Find duplicate RECEIPT_IDs where BARCODE and FINAL_QUANTITY are not unique\n",
    "duplicate_receipts_with_details = receipt_id_grouped[\n",
    "    (receipt_id_grouped['BARCODE'] > 1) | (receipt_id_grouped['FINAL_QUANTITY'] > 1)\n",
    "]\n",
    "\n",
    "# Display a sample of duplicate receipts with details for verification\n",
    "duplicate_receipts_with_details_sample = duplicate_receipts_with_details.head()\n",
    "\n",
    "# Output the results\n",
    "print(f\"Sample of Duplicate RECEIPT_IDs with Details: {duplicate_receipts_with_details_sample}\")\n",
    "print(f\"Number of Duplicate RECEIPT_IDs Identified: {duplicate_receipts_with_details.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IS_MULTI_ITEM\n",
       "False    44457\n",
       "True      5372\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assumptions:\n",
    "# - Each RECEIPT_ID corresponds to a single transaction.\n",
    "# - Duplicate RECEIPT_IDs represent valid multi-item transactions (e.g., multiple quantities of the same or different products purchased together).\n",
    "# - These should not be dropped as they provide critical details about multi-item transactions.\n",
    "\n",
    "# Findings:\n",
    "# - A total of 2,322 RECEIPT_IDs have multiple line items with unique combinations of BARCODE and FINAL_QUANTITY.\n",
    "# - These RECEIPT_IDs are valid and reflect real-world scenarios where customers purchase multiple items under one receipt.\n",
    "\n",
    "# Action Taken:\n",
    "# - Retaining all rows with duplicate RECEIPT_IDs to preserve the integrity of the dataset.\n",
    "# - Added a flag column 'IS_MULTI_ITEM' to identify these multi-item transactions for future analysis if needed.\n",
    "\n",
    "# Code to add a flag for multi-item transactions\n",
    "transactions['IS_MULTI_ITEM'] = transactions['RECEIPT_ID'].isin(duplicate_receipts_with_details['RECEIPT_ID'])\n",
    "\n",
    "# Verify the distribution of single-item vs. multi-item transactions\n",
    "multi_item_distribution = transactions['IS_MULTI_ITEM'].value_counts()\n",
    "\n",
    "# Output the distribution to check results\n",
    "multi_item_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Datasets are cleaned and Validated. \n",
    "# Let's Export the Cleaned Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned transactions dataset exported as 'cleaned_TRANSACTION_TAKEHOME.csv'.\n",
      "Cleaned products dataset exported as 'cleaned_PRODUCT_TAKEHOME.csv'.\n",
      "Cleaned users dataset exported as 'cleaned_USER_TAKEHOME.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Export the cleaned transactions dataset\n",
    "transactions.to_csv(\"cleaned_TRANSACTION_TAKEHOME.csv\", index=False)\n",
    "print(\"Cleaned transactions dataset exported as 'cleaned_TRANSACTION_TAKEHOME.csv'.\")\n",
    "\n",
    "# Export the cleaned products dataset\n",
    "products.to_csv(\"cleaned_PRODUCT_TAKEHOME.csv\", index=False)\n",
    "print(\"Cleaned products dataset exported as 'cleaned_PRODUCT_TAKEHOME.csv'.\")\n",
    "\n",
    "# Export the cleaned users dataset\n",
    "users.to_csv(\"cleaned_USER_TAKEHOME.csv\", index=False)\n",
    "print(\"Cleaned users dataset exported as 'cleaned_USER_TAKEHOME.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Data Exploration and Cleaning\n",
    "\n",
    "## Objective\n",
    "My goal during this process was to identify data quality issues, clean the datasets, and prepare them for analysis. Here's a summary of the key findings and actions taken for each dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## USER_TAKEHOME Dataset\n",
    "\n",
    "### Key Issues Identified:\n",
    "- Missing values in the `AGE` column.\n",
    "- Duplicate rows.\n",
    "- Inconsistent values in the `GENDER` and `STATE` columns.\n",
    "\n",
    "### Actions Taken:\n",
    "1. **Missing `AGE` Values:**\n",
    "   - Calculated `AGE` from the `BIRTH_DATE` column.\n",
    "   - Imputed missing `AGE` values with `-1` to retain rows for analysis while marking them as missing.\n",
    "2. **Duplicate Rows:**\n",
    "   - Removed all duplicate rows to avoid double counting.\n",
    "3. **Standardized Columns:**\n",
    "   - Cleaned and standardized the `GENDER` and `STATE` columns to ensure consistency.\n",
    "\n",
    "### Findings:\n",
    "- The majority of users fall between the ages of 20 and 60.\n",
    "- There was a significant number of missing `AGE` values, but they were flagged for further review.\n",
    "\n",
    "---\n",
    "\n",
    "## PRODUCTS_TAKEHOME Dataset\n",
    "\n",
    "### Key Issues Identified:\n",
    "- Missing values in key columns like `BARCODE`, `CATEGORY_1`, and `BRAND`.\n",
    "- Duplicate rows.\n",
    "- Inconsistent formatting in categorical columns like `CATEGORY_1` and `CATEGORY_2`.\n",
    "\n",
    "### Actions Taken:\n",
    "1. **Missing Values:**\n",
    "   - Replaced missing values in categorical columns (e.g., `CATEGORY_1`, `BRAND`) with `'unknown'` to retain these rows for analysis.\n",
    "   - Dropped rows with missing `BARCODE` since the barcode is essential for uniquely identifying products.\n",
    "2. **Duplicate Rows:**\n",
    "   - Removed duplicate rows based on `BARCODE` to ensure each product is unique.\n",
    "3. **Standardized Columns:**\n",
    "   - Cleaned and standardized `CATEGORY_1`, `CATEGORY_2`, `BRAND`, and `MANUFACTURER` columns for consistent analysis.\n",
    "\n",
    "### Findings:\n",
    "- `CATEGORY_1` had placeholder values like `Needs Review`, which were replaced with `'unknown'`.\n",
    "- There were duplicate `BARCODE` entries, which were removed to ensure integrity.\n",
    "\n",
    "---\n",
    "\n",
    "## TRANSACTION_TAKEHOME Dataset\n",
    "\n",
    "### Key Issues Identified:\n",
    "- Missing values in the `BARCODE` column for several transactions.\n",
    "- Inconsistent or invalid `PURCHASE_DATE` and `SCAN_DATE` values.\n",
    "- Duplicate rows and zero `FINAL_QUANTITY` values.\n",
    "- Missing values in `FINAL_SALE`.\n",
    "\n",
    "### Actions Taken:\n",
    "1. **Missing `BARCODE` Values:**\n",
    "   - Retained rows with missing barcodes but flagged them for further review.\n",
    "2. **Invalid Dates:**\n",
    "   - Corrected cases where `PURCHASE_DATE` was later than `SCAN_DATE` by setting `SCAN_DATE` equal to `PURCHASE_DATE`.\n",
    "3. **Zero `FINAL_QUANTITY` Values:**\n",
    "   - Replaced invalid `FINAL_QUANTITY` values (zero) with `1` when `FINAL_SALE` was valid.\n",
    "4. **Duplicate Rows:**\n",
    "   - Removed all duplicate rows to avoid overcounting transactions.\n",
    "5. **Standardized Columns:**\n",
    "   - Cleaned and standardized `STORE_NAME`, ensuring consistency across all entries.\n",
    "6. **Filled Missing `FINAL_SALE` Values:**\n",
    "   - Imputed missing `FINAL_SALE` values using the mean of existing values to ensure accurate financial analysis.\n",
    "7. **Checked for Duplicate `RECEIPT_ID`:**\n",
    "   - Grouped `RECEIPT_ID` by `BARCODE` and `FINAL_QUANTITY` to determine whether the receipt was duplicated based on unique product purchases.\n",
    "\n",
    "### Findings:\n",
    "- Certain stores (e.g., Aldi) had a significant number of transactions with missing barcodes.\n",
    "- A few invalid dates were corrected, ensuring accurate date-based analysis.\n",
    "- Multi-item receipts were flagged and preserved for further insights.\n",
    "- Missing `FINAL_SALE` values were successfully imputed based on the mean.\n",
    "- Duplicate `RECEIPT_IDs` were analyzed based on their associated products and quantities.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary of Actions\n",
    "- The datasets are now clean, standardized, and ready for analysis.\n",
    "- All missing values, duplicates, and inconsistencies have been addressed to the best of my ability while preserving the integrity of the data.\n",
    "- Placeholder values like `-1` and `'unknown'` were used where necessary to retain rows for future analysis.\n",
    "\n",
    "## Next Steps\n",
    "1. Use the cleaned datasets to generate insights and trends.\n",
    "2. Proceed with writing SQL queries to answer the assessment questions.\n",
    "3. Communicate findings to stakeholders and highlight any remaining data gaps (e.g., missing `BARCODE` values in transactions).\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
